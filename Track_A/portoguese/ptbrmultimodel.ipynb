{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10596204,"sourceType":"datasetVersion","datasetId":6558581},{"sourceId":10596581,"sourceType":"datasetVersion","datasetId":6558827}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Imports & Setup (Same as before)\n# -------------------------------------------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AutoModel, AutoTokenizer\nfrom tqdm import tqdm\nimport os\n","metadata":{"id":"KI3yCJWMQ5WD","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:30.715091Z","iopub.execute_input":"2025-01-27T21:32:30.715385Z","iopub.status.idle":"2025-01-27T21:32:30.720727Z","shell.execute_reply.started":"2025-01-27T21:32:30.715362Z","shell.execute_reply":"2025-01-27T21:32:30.719345Z"}},"outputs":[],"execution_count":184},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PX8gy3z6RS6b","outputId":"03aeea81-a135-4707-d873-db755e12cb31","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:30.723138Z","iopub.execute_input":"2025-01-27T21:32:30.723403Z","iopub.status.idle":"2025-01-27T21:32:30.740800Z","shell.execute_reply.started":"2025-01-27T21:32:30.723382Z","shell.execute_reply":"2025-01-27T21:32:30.739965Z"}},"outputs":[{"execution_count":185,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7bd0eeb4a450>"},"metadata":{}}],"execution_count":185},{"cell_type":"code","source":"TRAIN_PATH = \"/kaggle/input/ptbrdataset/ptbrtrain.csv\"\nVAL_PATH   = \"/kaggle/input/ptbrdataset/ptbrval.csv\"\nTEST_PATH  = \"/kaggle/input/ptbrdataset/ptbrtest.csv\"\n\ntrain_df = pd.read_csv(TRAIN_PATH)\nval_df   = pd.read_csv(VAL_PATH)\ntest_df  = pd.read_csv(TEST_PATH)\n","metadata":{"id":"pT_l4ECRRbKN","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:30.741823Z","iopub.execute_input":"2025-01-27T21:32:30.742100Z","iopub.status.idle":"2025-01-27T21:32:30.770399Z","shell.execute_reply.started":"2025-01-27T21:32:30.742081Z","shell.execute_reply":"2025-01-27T21:32:30.769744Z"}},"outputs":[],"execution_count":186},{"cell_type":"code","source":"# Instead of a single LABEL_VAR, define multiple label columns:\nLABEL_COLS = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\nTEXT_VAR   = \"text\"","metadata":{"id":"rDWDRDJ5Renf","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:30.771676Z","iopub.execute_input":"2025-01-27T21:32:30.771900Z","iopub.status.idle":"2025-01-27T21:32:30.775478Z","shell.execute_reply.started":"2025-01-27T21:32:30.771879Z","shell.execute_reply":"2025-01-27T21:32:30.774744Z"}},"outputs":[],"execution_count":187},{"cell_type":"code","source":"# 3. Load Tokenizer & Model for Embedding Extraction\n# -------------------------------------------------------\nmodel_name_1 = \"Hate-speech-CNERG/dehatebert-mono-portugese\"\nmodel_name_2 = \"MFrazz/distilbert-base-uncased-Portfolio-Pred\"\n\ntext_tokenizer_1 = AutoTokenizer.from_pretrained(model_name_1)\ntext_model_1 = AutoModel.from_pretrained(model_name_1).to(device)\n\ntext_tokenizer_2 = AutoTokenizer.from_pretrained(model_name_2)\ntext_model_2 = AutoModel.from_pretrained(model_name_2).to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P8u8RiC5Rg9Z","outputId":"93af575a-69a8-4d4e-9879-fd38f8d9c785","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:30.776772Z","iopub.execute_input":"2025-01-27T21:32:30.777074Z","iopub.status.idle":"2025-01-27T21:32:32.408809Z","shell.execute_reply.started":"2025-01-27T21:32:30.777041Z","shell.execute_reply":"2025-01-27T21:32:32.407477Z"}},"outputs":[],"execution_count":188},{"cell_type":"code","source":"# Collect the counts of \"1\" for each label\ncounts_ones = []\nfor label in LABEL_COLS:\n    # Count how many rows in train_df have this label = 1\n    num_ones = (train_df[label] == 1).sum()\n    counts_ones.append((label, num_ones))\n\n# Build a DataFrame for plotting\ncounts_df = pd.DataFrame(counts_ones, columns=[\"label\", \"count_of_1\"])\n\nplt.figure(figsize=(8, 6))\nsns.barplot(\n    x=\"label\",\n    y=\"count_of_1\",\n    data=counts_df,\n    palette=\"Set2\"\n)\nplt.title(\"Counts of 1 for Each Label\")\nplt.xlabel(\"Label\")\nplt.ylabel(\"Count of 1\")\nplt.tight_layout()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"id":"GMKGxX6iKo49","outputId":"d4320bc8-1613-43be-e938-b1c437c5c468","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:32.410632Z","iopub.execute_input":"2025-01-27T21:32:32.411037Z","iopub.status.idle":"2025-01-27T21:32:32.643610Z","shell.execute_reply.started":"2025-01-27T21:32:32.410995Z","shell.execute_reply":"2025-01-27T21:32:32.642751Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":189},{"cell_type":"code","source":"def extract_multi_model_embeddings(df, save_path,\n                                   model1, tokenizer1,\n                                   model2, tokenizer2,\n                                   max_length=128):\n    \"\"\"\n    Extract embeddings from TWO transformer models, then concatenate.\n    \"\"\"\n    if os.path.exists(save_path):\n        print(f\"Embeddings already exist at {save_path}\")\n        return torch.load(save_path)\n\n    embeddings = {}\n    model1.eval()\n    model2.eval()\n\n    with torch.no_grad():\n        for idx, row in tqdm(df.iterrows(), desc=\"Extracting text embeddings\", total=len(df)):\n            text_sample = row[TEXT_VAR]\n            text_sample = text_sample if isinstance(text_sample, str) else \"\"\n\n            # 1) Model 1\n            inputs_1 = tokenizer1(\n                text_sample,\n                padding=\"max_length\",\n                truncation=True,\n                max_length=max_length,\n                return_tensors=\"pt\"\n            ).to(device)\n            outputs_1 = model1(**inputs_1)\n            cls_1 = outputs_1.last_hidden_state[:, 0, :]  # shape: (1, 768) for DistilRoBERTa\n\n            # 2) Model 2\n            inputs_2 = tokenizer2(\n                text_sample,\n                padding=\"max_length\",\n                truncation=True,\n                max_length=max_length,\n                return_tensors=\"pt\"\n            ).to(device)\n            outputs_2 = model2(**inputs_2)\n            cls_2 = outputs_2.last_hidden_state[:, 0, :]  # shape: (1, 768) for DistilBERT\n\n            # 3) Concatenate\n            # shape: (1, 768) + (1, 768) => (1, 1536)\n            combined = torch.cat((cls_1, cls_2), dim=1)\n\n            # Store in dictionary\n            embeddings[idx] = combined.cpu()\n\n    torch.save(embeddings, save_path)\n    return embeddings\n\n# Extract embeddings from both models & combine\ntrain_text_embeddings = extract_multi_model_embeddings(\n    train_df,\n    \"train_text_embeddings.pt\",\n    text_model_1, text_tokenizer_1,\n    text_model_2, text_tokenizer_2,\n    max_length=128\n)\n\nval_text_embeddings = extract_multi_model_embeddings(\n    val_df,\n    \"val_text_embeddings.pt\",\n    text_model_1, text_tokenizer_1,\n    text_model_2, text_tokenizer_2,\n    max_length=128\n)\n\ntest_text_embeddings = extract_multi_model_embeddings(\n    test_df,\n    \"test_text_embeddings.pt\",\n    text_model_1, text_tokenizer_1,\n    text_model_2, text_tokenizer_2,\n    max_length=128\n)\n# -------------------------------------------------------\n# >>> MULTIPLE MODELS CODE END <<<","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2bTxzSgPR7Ss","outputId":"53e20cc5-ea8f-4cdb-914d-2bdb00307879","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:32.644458Z","iopub.execute_input":"2025-01-27T21:32:32.644685Z","iopub.status.idle":"2025-01-27T21:32:32.959261Z","shell.execute_reply.started":"2025-01-27T21:32:32.644664Z","shell.execute_reply":"2025-01-27T21:32:32.958315Z"}},"outputs":[{"name":"stdout","text":"Embeddings already exist at train_text_embeddings.pt\nEmbeddings already exist at val_text_embeddings.pt\nEmbeddings already exist at test_text_embeddings.pt\n","output_type":"stream"}],"execution_count":190},{"cell_type":"code","source":"# 5. Prepare Embeddings (CHANGED for Multi‐Label)\n# -------------------------------------------------------\ndef prepare_text_embeddings(text_embeddings, df, label_cols=None, has_labels=True):\n    \"\"\"\n    For each row in df, gather the text embedding and (optionally) the labels.\n    label_cols: list of columns for multi-label (e.g. [\"anger\", \"fear\", \"joy\", ...])\n    \"\"\"\n    combined_embeddings = []\n    labels = []\n\n    for idx, row in df.iterrows():\n        if idx not in text_embeddings:\n            continue\n        # Get the [CLS] embedding\n        text_embedding = text_embeddings[idx].squeeze()  # shape: (768,)\n        combined_embeddings.append(text_embedding)\n\n        if has_labels and label_cols is not None:\n            # Collect all label columns as a float vector\n            label_vector = row[label_cols].values.astype(float)  # shape: (5,)\n            labels.append(label_vector)\n\n    # Convert to Tensors\n    if has_labels and label_cols is not None:\n        X = torch.stack(combined_embeddings)\n        Y = torch.tensor(labels, dtype=torch.float)  # multi-label => float\n        return X, Y\n    else:\n        return torch.stack(combined_embeddings)\n\nX_train, y_train = prepare_text_embeddings(train_text_embeddings, train_df, LABEL_COLS, has_labels=True)\nX_val,   y_val   = prepare_text_embeddings(val_text_embeddings,   val_df,   LABEL_COLS, has_labels=True)\nX_test           = prepare_text_embeddings(test_text_embeddings,  test_df,  LABEL_COLS, has_labels=False)\n\nprint(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\nprint(\"X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\nprint(\"X_test: \", X_test.shape)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ykURmiwuSCBQ","outputId":"1506efdd-8b14-4c3f-8195-42468817be22","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:32.962055Z","iopub.execute_input":"2025-01-27T21:32:32.962322Z","iopub.status.idle":"2025-01-27T21:32:33.975253Z","shell.execute_reply.started":"2025-01-27T21:32:32.962300Z","shell.execute_reply":"2025-01-27T21:32:33.974445Z"}},"outputs":[{"name":"stdout","text":"X_train: torch.Size([2226, 1536]) y_train: torch.Size([2226, 6])\nX_val:   torch.Size([200, 1536]) y_val:   torch.Size([200, 6])\nX_test:  torch.Size([2226, 1536])\n","output_type":"stream"}],"execution_count":191},{"cell_type":"code","source":"\ndef balance_multilabel_data(X, Y):\n    \"\"\"\n    Oversample minority label-combinations in a multi-label setting.\n    1. Convert each row's label vector (like [1,0,1,0,0]) into a tuple (1.0,0.0,1.0,0.0,0.0).\n    2. Count how many rows share that exact tuple (i.e., label combination).\n    3. Duplicate those rows until they match the frequency of the most common combination.\n\n    NOTE: This lumps each distinct 5-label pattern as one \"class.\"\n    If every row has a unique pattern, this won't help much.\n    \"\"\"\n    from collections import Counter\n\n    # Convert each label row to a tuple\n    label_tuples = [tuple(row.tolist()) for row in Y]\n    class_counts = Counter(label_tuples)\n    max_count = max(class_counts.values())\n\n    # We'll store duplicates in lists, then convert to tensors\n    balanced_embeddings = []\n    balanced_labels = []\n\n    for i, label_tuple in enumerate(label_tuples):\n        balanced_embeddings.append(X[i])\n        balanced_labels.append(label_tuple)\n\n        current_count = class_counts[label_tuple]\n        # e.g., duplicates_needed = how many times to replicate?\n        duplicates_needed = int((max_count - current_count) / current_count)\n\n        for _ in range(duplicates_needed):\n            balanced_embeddings.append(X[i])\n            balanced_labels.append(label_tuple)\n\n    balanced_embeddings = torch.stack(balanced_embeddings)\n    balanced_labels = torch.tensor(balanced_labels, dtype=torch.float)\n    print(f\"Original dataset size: {X.shape[0]}\")\n    print(f\"Balanced dataset size: {balanced_embeddings.shape[0]}\")\n    return balanced_embeddings, balanced_labels\n\n# Call our new multi-label balancing function\nX_train, y_train = balance_multilabel_data(X_train, y_train)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7oz_zljhMpnm","outputId":"139217d6-e73d-478e-9955-c9bb731c3a52","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:33.976875Z","iopub.execute_input":"2025-01-27T21:32:33.977162Z","iopub.status.idle":"2025-01-27T21:32:34.157768Z","shell.execute_reply.started":"2025-01-27T21:32:33.977138Z","shell.execute_reply":"2025-01-27T21:32:34.157059Z"}},"outputs":[{"name":"stdout","text":"Original dataset size: 2226\nBalanced dataset size: 19649\n","output_type":"stream"}],"execution_count":192},{"cell_type":"code","source":"# 6. Define Multi‐Label MLP Model (CHANGED)\n# -------------------------------------------------------\nclass MLPModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, dropout_p=0.5):\n        super(MLPModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n        self.relu = nn.ReLU()\n        self.dropout1 = nn.Dropout(p=dropout_p)\n        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n        self.dropout2 = nn.Dropout(p=dropout_p)\n        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n        # For multi‐label, we *do not* apply softmax, we will use BCEWithLogitsLoss\n\n    def forward(self, x):\n        x = self.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = self.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)            # shape: (batch_size, 5)\n        # No softmax here for multi‐label. Return raw logits for BCEWithLogitsLoss\n        return x\n","metadata":{"id":"j2JzYjEHSMu7","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:34.158584Z","iopub.execute_input":"2025-01-27T21:32:34.158797Z","iopub.status.idle":"2025-01-27T21:32:34.164403Z","shell.execute_reply.started":"2025-01-27T21:32:34.158778Z","shell.execute_reply":"2025-01-27T21:32:34.163574Z"}},"outputs":[],"execution_count":193},{"cell_type":"code","source":"# Model & Hyperparams\ninput_dim    = X_train.shape[1]        # e.g. 768\nhidden_dim   = [786, 512]             # can be tuned\noutput_dim   = len(LABEL_COLS)        # 5 for multi‐label\ndropout_p    = 0.3\nnum_epochs   = 10\nbatch_size   = 16\nlearning_rate = 1e-4\n\nmodel = MLPModel(input_dim, hidden_dim, output_dim, dropout_p).to(device)","metadata":{"id":"TSkqLDOVSVyh","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:34.165640Z","iopub.execute_input":"2025-01-27T21:32:34.165954Z","iopub.status.idle":"2025-01-27T21:32:34.191827Z","shell.execute_reply.started":"2025-01-27T21:32:34.165902Z","shell.execute_reply":"2025-01-27T21:32:34.191045Z"}},"outputs":[],"execution_count":194},{"cell_type":"code","source":"# 7. CHANGED: Use BCEWithLogitsLoss (for multi‐label)\n# -------------------------------------------------------\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"id":"qeMpwVS2SYam","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:34.192858Z","iopub.execute_input":"2025-01-27T21:32:34.193170Z","iopub.status.idle":"2025-01-27T21:32:34.197295Z","shell.execute_reply.started":"2025-01-27T21:32:34.193140Z","shell.execute_reply":"2025-01-27T21:32:34.196552Z"}},"outputs":[],"execution_count":195},{"cell_type":"code","source":"# >>> LR DECAY CODE: Define a scheduler after creating optimizer <<<\n#>>>from torch.optim.lr_scheduler import ReduceLROnPlateau\n\n#scheduler = ReduceLROnPlateau(\n   # optimizer,\n  #  mode='min',    # We want to reduce LR if val_loss does not improve\n  #  factor=0.5,    # Reduce the LR by half\n   # patience=3,    # Number of epochs with no improvement before reducing\n   # verbose=True)\n# >>> LR DECAY CODE ENDS <<<","metadata":{"id":"vnCEYt0wgWSP","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:34.198108Z","iopub.execute_input":"2025-01-27T21:32:34.198331Z","iopub.status.idle":"2025-01-27T21:32:34.207505Z","shell.execute_reply.started":"2025-01-27T21:32:34.198312Z","shell.execute_reply":"2025-01-27T21:32:34.206744Z"}},"outputs":[],"execution_count":196},{"cell_type":"code","source":"# 8. Dataloaders\n# -------------------------------------------------------\ntrain_dataset = TensorDataset(X_train, y_train)\nval_dataset   = TensorDataset(X_val,   y_val)\ntest_dataset  = TensorDataset(X_test)  # no labels for test\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader   = DataLoader(val_dataset,   batch_size=batch_size)\ntest_loader  = DataLoader(test_dataset,  batch_size=batch_size)","metadata":{"id":"RIiqLiirSbo5","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:34.208431Z","iopub.execute_input":"2025-01-27T21:32:34.208699Z","iopub.status.idle":"2025-01-27T21:32:34.231408Z","shell.execute_reply.started":"2025-01-27T21:32:34.208665Z","shell.execute_reply":"2025-01-27T21:32:34.230468Z"}},"outputs":[],"execution_count":197},{"cell_type":"code","source":"# 9. Metrics for Multi‐Label (CHANGED)\n# -------------------------------------------------------\ndef calculate_metrics(preds, labels):\n    \"\"\"\n    preds, labels are lists (or arrays) of shape (N, 5).\n    We'll do an example with macro avg for PRF.\n    \"\"\"\n    preds = np.array(preds)\n    labels = np.array(labels)\n\n    # Example: For each label, threshold at 0.5\n    # (We already do that during loop, but let's be explicit.)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        labels, preds, average='macro', zero_division=0\n    )\n    # Multi‐label “accuracy” can be ambiguous.\n    # Some do “exact match ratio”, etc. We'll do a simple overall average:\n    accuracy = (preds == labels).mean()\n\n    return accuracy, precision, recall, f1","metadata":{"id":"7biPQklUSeXM","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:34.233724Z","iopub.execute_input":"2025-01-27T21:32:34.233954Z","iopub.status.idle":"2025-01-27T21:32:34.244481Z","shell.execute_reply.started":"2025-01-27T21:32:34.233934Z","shell.execute_reply":"2025-01-27T21:32:34.243785Z"}},"outputs":[],"execution_count":198},{"cell_type":"code","source":"# 10. Train and Validate (CHANGES in Predictions)\n# -------------------------------------------------------\ndef train_and_save_best_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, save_dir):\n    best_f1 = -float('inf')\n    best_model_path = None\n\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0\n        all_train_preds, all_train_labels = [], []\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)  # shape: (batch_size, 5)\n            # For BCEWithLogitsLoss, labels should be float\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n\n            # Convert logits -> probabilities -> binary predictions\n            preds = (torch.sigmoid(outputs) > 0.5).float()\n            all_train_preds.extend(preds.cpu().tolist())\n            all_train_labels.extend(labels.cpu().tolist())\n\n        # Training metrics\n        train_accuracy, train_precision, train_recall, train_f1 = calculate_metrics(all_train_preds, all_train_labels)\n\n        # Validation\n        model.eval()\n        val_loss = 0\n        all_val_preds, all_val_labels = [], []\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)  # shape: (batch_size, 5)\n\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n\n                preds = (torch.sigmoid(outputs) > 0.5).float()\n                all_val_preds.extend(preds.cpu().tolist())\n                all_val_labels.extend(labels.cpu().tolist())\n\n        val_accuracy, val_precision, val_recall, val_f1 = calculate_metrics(all_val_preds, all_val_labels)\n\n        print(\n            f\"Epoch {epoch+1}/{num_epochs} \"\n            f\"Train Loss: {train_loss/len(train_loader):.4f}, \"\n            f\"Train Acc: {train_accuracy:.4f}, F1: {train_f1:.4f} | \"\n            f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n            f\"Val Acc: {val_accuracy:.4f}, F1: {val_f1:.4f}\"\n        )\n\n        #>>> LR DECAY CODE: Step the scheduler with the validation loss <<<\n        # \"scheduler.step\" expects a metric. If val loss doesn't improve enough,\n        # it will reduce the LR after 'patience' epochs.\n        #scheduler.step(val_loss)\n        # >>> LR DECAY CODE ENDS <<<\n\n        # Save best model by val_f1\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            best_model_path = os.path.join(save_dir, f\"best_model_epoch_{epoch+1}_f1_{val_f1:.4f}.pth\")\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"Best model saved with F1: {val_f1:.4f} at epoch {epoch+1}\")\n\n    return best_model_path\n\nsave_dir = \"./models\"\nos.makedirs(save_dir, exist_ok=True)\n\nbest_model_path = train_and_save_best_model(\n    model, train_loader, val_loader, criterion, optimizer, num_epochs, save_dir\n)\n\nprint(f\"Best model saved at: {best_model_path}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHid0LPJShaz","outputId":"ebcf3c16-be5d-48b0-f11c-693f11eb9142","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:32:34.245517Z","iopub.execute_input":"2025-01-27T21:32:34.245709Z","iopub.status.idle":"2025-01-27T21:33:04.978119Z","shell.execute_reply.started":"2025-01-27T21:32:34.245692Z","shell.execute_reply":"2025-01-27T21:33:04.977280Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10 Train Loss: 0.3431, Train Acc: 0.8488, F1: 0.7630 | Val Loss: 0.5175, Val Acc: 0.7792, F1: 0.2238\nBest model saved with F1: 0.2238 at epoch 1\nEpoch 2/10 Train Loss: 0.1778, Train Acc: 0.9308, F1: 0.9022 | Val Loss: 0.4987, Val Acc: 0.7858, F1: 0.3078\nBest model saved with F1: 0.3078 at epoch 2\nEpoch 3/10 Train Loss: 0.1221, Train Acc: 0.9540, F1: 0.9365 | Val Loss: 0.4772, Val Acc: 0.8108, F1: 0.3335\nBest model saved with F1: 0.3335 at epoch 3\nEpoch 4/10 Train Loss: 0.0908, Train Acc: 0.9676, F1: 0.9556 | Val Loss: 0.5023, Val Acc: 0.8158, F1: 0.2938\nEpoch 5/10 Train Loss: 0.0726, Train Acc: 0.9749, F1: 0.9659 | Val Loss: 0.5903, Val Acc: 0.7992, F1: 0.3354\nBest model saved with F1: 0.3354 at epoch 5\nEpoch 6/10 Train Loss: 0.0620, Train Acc: 0.9783, F1: 0.9705 | Val Loss: 0.5348, Val Acc: 0.8183, F1: 0.3182\nEpoch 7/10 Train Loss: 0.0520, Train Acc: 0.9822, F1: 0.9760 | Val Loss: 0.5896, Val Acc: 0.8117, F1: 0.3002\nEpoch 8/10 Train Loss: 0.0462, Train Acc: 0.9843, F1: 0.9788 | Val Loss: 0.6065, Val Acc: 0.8033, F1: 0.2755\nEpoch 9/10 Train Loss: 0.0409, Train Acc: 0.9859, F1: 0.9809 | Val Loss: 0.5862, Val Acc: 0.8275, F1: 0.3368\nBest model saved with F1: 0.3368 at epoch 9\nEpoch 10/10 Train Loss: 0.0355, Train Acc: 0.9878, F1: 0.9833 | Val Loss: 0.5834, Val Acc: 0.8300, F1: 0.3109\nBest model saved at: ./models/best_model_epoch_9_f1_0.3368.pth\n","output_type":"stream"}],"execution_count":199},{"cell_type":"code","source":"# 11. Test Predictions (CHANGES for Multi‐Label)\n# -------------------------------------------------------\ndef predict_and_generate_submission(test_loader, best_model_path, submission_file_path):\n    # Reload a fresh model\n    inference_model = MLPModel(input_dim, hidden_dim, output_dim, dropout_p).to(device)\n    inference_model.load_state_dict(torch.load(best_model_path))\n    inference_model.eval()\n\n    # We'll store multi‐label predictions as 0/1 for each label\n    test_predictions = []\n    with torch.no_grad():\n        for (inputs,) in test_loader:  # Each batch is a tuple containing only X\n            inputs = inputs.to(device)\n            outputs = inference_model(inputs)\n            preds = (torch.sigmoid(outputs) > 0.5).int()  # shape: (batch_size, 5)\n            test_predictions.append(preds.cpu())\n\n    test_predictions = torch.cat(test_predictions, dim=0).numpy()  # shape: (num_samples, 5)\n\n    # Build submission DataFrame\n    submission_df = pd.DataFrame({\n        \"id\": test_df[\"id\"],  # or whatever your ID is\n        \"anger_pred\":    test_predictions[:, 0],\n        \"disgust_pred\": test_predictions[:, 1],\n        \"fear_pred\":     test_predictions[:, 2],\n        \"joy_pred\":      test_predictions[:, 3],\n        \"sadness_pred\": test_predictions[:, 4],\n        \"surprise_pred\":test_predictions[:, 5]\n    })\n\n    submission_df.to_csv(submission_file_path, index=False)\n    print(f\"Submission file saved to {submission_file_path}\")\n    return submission_df\n\nsubmission_file_path = \"submission.csv\"\nsubmission_df = predict_and_generate_submission(test_loader, best_model_path, submission_file_path)\nsubmission_df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"kvMYTGpMSmf9","outputId":"e9cf39d0-8129-40aa-8617-55e29ec6a1ae","trusted":true,"execution":{"iopub.status.busy":"2025-01-27T21:33:04.978976Z","iopub.execute_input":"2025-01-27T21:33:04.979297Z","iopub.status.idle":"2025-01-27T21:33:05.095086Z","shell.execute_reply.started":"2025-01-27T21:33:04.979265Z","shell.execute_reply":"2025-01-27T21:33:05.094367Z"}},"outputs":[{"name":"stdout","text":"Submission file saved to submission.csv\n","output_type":"stream"},{"execution_count":200,"output_type":"execute_result","data":{"text/plain":"                        id  anger_pred  disgust_pred  fear_pred  joy_pred  \\\n0  ptbr_test_track_a_00001           0             0          0         0   \n1  ptbr_test_track_a_00002           0             0          0         0   \n2  ptbr_test_track_a_00003           1             0          0         1   \n3  ptbr_test_track_a_00004           0             0          0         0   \n4  ptbr_test_track_a_00005           0             0          0         1   \n\n   sadness_pred  surprise_pred  \n0             1              0  \n1             0              0  \n2             0              0  \n3             0              0  \n4             0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anger_pred</th>\n      <th>disgust_pred</th>\n      <th>fear_pred</th>\n      <th>joy_pred</th>\n      <th>sadness_pred</th>\n      <th>surprise_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ptbr_test_track_a_00001</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ptbr_test_track_a_00002</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ptbr_test_track_a_00003</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ptbr_test_track_a_00004</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ptbr_test_track_a_00005</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":200},{"cell_type":"code","source":"","metadata":{"id":"Tla8NpESSvNV","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
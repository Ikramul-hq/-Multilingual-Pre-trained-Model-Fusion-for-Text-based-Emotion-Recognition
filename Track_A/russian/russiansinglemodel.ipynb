{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10419045,"sourceType":"datasetVersion","datasetId":6457498},{"sourceId":10606292,"sourceType":"datasetVersion","datasetId":6565564},{"sourceId":10606438,"sourceType":"datasetVersion","datasetId":6565684}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Imports & Setup (Same as before)\n# -------------------------------------------------------\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AutoModel, AutoTokenizer\nfrom tqdm import tqdm\nimport os\n","metadata":{"id":"KI3yCJWMQ5WD","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:05.467630Z","iopub.execute_input":"2025-01-29T18:31:05.467954Z","iopub.status.idle":"2025-01-29T18:31:05.473268Z","shell.execute_reply.started":"2025-01-29T18:31:05.467926Z","shell.execute_reply":"2025-01-29T18:31:05.472314Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(42)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PX8gy3z6RS6b","outputId":"69de4dce-fd93-4fe8-b604-bcc8d2fe76a8","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:05.474303Z","iopub.execute_input":"2025-01-29T18:31:05.474518Z","iopub.status.idle":"2025-01-29T18:31:05.491002Z","shell.execute_reply.started":"2025-01-29T18:31:05.474499Z","shell.execute_reply":"2025-01-29T18:31:05.490336Z"}},"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f99b5f7af10>"},"metadata":{}}],"execution_count":83},{"cell_type":"code","source":"TRAIN_PATH = \"/kaggle/input/russiadataset/rus.csv\"\nVAL_PATH   = \"/kaggle/input/russiadataset/rusval.csv\"\nTEST_PATH  = \"/kaggle/input/russiadataset/rustest.csv\"\n\ntrain_df = pd.read_csv(TRAIN_PATH)\nval_df   = pd.read_csv(VAL_PATH)\ntest_df  = pd.read_csv(TEST_PATH)\n","metadata":{"id":"pT_l4ECRRbKN","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:05.492660Z","iopub.execute_input":"2025-01-29T18:31:05.492873Z","iopub.status.idle":"2025-01-29T18:31:05.520811Z","shell.execute_reply.started":"2025-01-29T18:31:05.492854Z","shell.execute_reply":"2025-01-29T18:31:05.520139Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:05.521961Z","iopub.execute_input":"2025-01-29T18:31:05.522236Z","iopub.status.idle":"2025-01-29T18:31:05.530884Z","shell.execute_reply.started":"2025-01-29T18:31:05.522214Z","shell.execute_reply":"2025-01-29T18:31:05.530142Z"}},"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"                        id                                               text  \\\n0  rus_train_track_a_00001  …каждый индивидуум есть продукт не только суще...   \n1  rus_train_track_a_00002                                    Ужасно противно   \n2  rus_train_track_a_00003             Охуеть я в шоке Пойду выпью что нибудь   \n3  rus_train_track_a_00004                           Так спина болит( ужас(((   \n4  rus_train_track_a_00005                                   леха,мне страшно   \n\n   anger  disgust  fear  joy  sadness  surprise  \n0      0        0     0    0        0         0  \n1      0        1     0    0        0         0  \n2      0        0     0    0        0         1  \n3      0        0     0    0        1         0  \n4      0        0     1    0        0         0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text</th>\n      <th>anger</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>sadness</th>\n      <th>surprise</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rus_train_track_a_00001</td>\n      <td>…каждый индивидуум есть продукт не только суще...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rus_train_track_a_00002</td>\n      <td>Ужасно противно</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>rus_train_track_a_00003</td>\n      <td>Охуеть я в шоке Пойду выпью что нибудь</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>rus_train_track_a_00004</td>\n      <td>Так спина болит( ужас(((</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>rus_train_track_a_00005</td>\n      <td>леха,мне страшно</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":85},{"cell_type":"code","source":"# Instead of a single LABEL_VAR, define multiple label columns:\nLABEL_COLS = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\nTEXT_VAR   = \"text\"","metadata":{"id":"rDWDRDJ5Renf","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:05.531756Z","iopub.execute_input":"2025-01-29T18:31:05.532092Z","iopub.status.idle":"2025-01-29T18:31:05.543181Z","shell.execute_reply.started":"2025-01-29T18:31:05.532034Z","shell.execute_reply":"2025-01-29T18:31:05.542391Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"# 3. Load Tokenizer & Model for Embedding Extraction\n# -------------------------------------------------------\nmodel_name = \"MaxKazak/ruBert-base-russian-emotion-detection\"\ntext_tokenizer = AutoTokenizer.from_pretrained(model_name)\ntext_model = AutoModel.from_pretrained(model_name).to(device)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P8u8RiC5Rg9Z","outputId":"7cb689e0-763e-466f-8031-e7e02b69cf59","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:05.543815Z","iopub.execute_input":"2025-01-29T18:31:05.544103Z","iopub.status.idle":"2025-01-29T18:31:06.189491Z","shell.execute_reply.started":"2025-01-29T18:31:05.544076Z","shell.execute_reply":"2025-01-29T18:31:06.188685Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"# Collect the counts of \"1\" for each label\ncounts_ones = []\nfor label in LABEL_COLS:\n    # Count how many rows in train_df have this label = 1\n    num_ones = (train_df[label] == 1).sum()\n    counts_ones.append((label, num_ones))\n\n# Build a DataFrame for plotting\ncounts_df = pd.DataFrame(counts_ones, columns=[\"label\", \"count_of_1\"])\n\nplt.figure(figsize=(8, 6))\nsns.barplot(\n    x=\"label\",\n    y=\"count_of_1\",\n    data=counts_df,\n    palette=\"Set2\"\n)\nplt.title(\"Counts of 1 for Each Label\")\nplt.xlabel(\"Label\")\nplt.ylabel(\"Count of 1\")\nplt.tight_layout()\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"id":"GMKGxX6iKo49","outputId":"af54ff1b-66a8-4357-d142-9bb154f2fc39","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:06.190680Z","iopub.execute_input":"2025-01-29T18:31:06.190909Z","iopub.status.idle":"2025-01-29T18:31:06.388937Z","shell.execute_reply.started":"2025-01-29T18:31:06.190889Z","shell.execute_reply":"2025-01-29T18:31:06.388113Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAxYAAAJOCAYAAAAqFJGJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABH+ElEQVR4nO3deXxU1f3/8feE7AmTkEASKCGEnbAKCAQQF4IpIoIiFX8IgbIosiiIWlrKppSWb2XRBvxiFRClWLBuiMiOCmGRTSAQAdkqBBANYU1Ccn5/+Mh8GVlMOAlDyOv5eMzjwZxz7r2fOzeTzJt7zx2HMcYIAAAAACx4eboAAAAAACUfwQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIA4HL8+HE9+uijCg8Pl8Ph0NSpU2+LbXnK2LFj5XA49MMPP3i6FM2ePVsOh0Nff/11ka0zf/8AQCJYAChl9u/fryeffFLVqlWTv7+/nE6nWrdurWnTpunChQueLk+SNH36dM2ePdsj2x42bJg+//xzjRw5UnPnztVvf/vba45977339MQTT6hmzZpyOBy65557im1bRcHhcFzz8dRTTxXrtm9U7969FRwc7OkyAKBAvD1dAADcLJ9++qm6desmPz8/9erVS/Xr11d2dra++uorPf/889q1a5dmzpzp6TI1ffp0lS9fXr17977p2165cqU6d+6sESNG/OrYGTNmaPPmzbrzzjt16tSpYt1WUWnfvr169ep1RXutWrVuWg0AcLsiWAAoFQ4cOKDu3bsrJiZGK1euVMWKFV19gwYN0r59+/Tpp596sMJbw4kTJxQaGlqgsXPnztVvfvMbeXl5qX79+sW6rYK4ePGifH195eV17ZPxtWrV0hNPPFFk2wQA/B8uhQJQKkyaNElnz57Vm2++6RYq8tWoUUPPPPOM6/mlS5f00ksvqXr16vLz81PVqlX1xz/+UVlZWW7LORwOjR079or1Va1a1e2MQ/717WvXrtXw4cNVoUIFBQUF6eGHH9bJkyfdltu1a5fWrFnjukwn/xKjnJwcjRs3TjVr1pS/v7/Cw8PVpk0bLVu27Ff3/7vvvlO3bt0UFhamwMBAtWzZ0i1I5ddnjFFycrJr29cTHR193Q/x1/Jr2/q1WiVp9erVcjgcmj9/vkaNGqXf/OY3CgwMVGZmZqHr+aUvv/xS3bp1U5UqVeTn56fo6GgNGzbsqpfK7dmzR7/73e9UoUIFBQQEqHbt2vrTn/50xbiMjAz17t1boaGhCgkJUZ8+fXT+/HnrWiXp0KFDevrpp1W7dm0FBAQoPDxc3bp108GDB686/vz583ryyScVHh4up9OpXr166aeffrpi3Geffaa77rpLQUFBKlu2rDp27Khdu3YVSc0Abk+csQBQKnzyySeqVq2aWrVqVaDx/fr105w5c/Too4/queee04YNGzRx4kTt3r1bH3zwwQ3XMWTIEJUrV05jxozRwYMHNXXqVA0ePFjvvfeeJGnq1KkaMmSIgoODXR9QIyMjJf08UXbixInq16+fmjdvrszMTH399dfasmWL2rdvf81tHj9+XK1atdL58+c1dOhQhYeHa86cOXrooYe0cOFCPfzww2rbtq3mzp2rnj17XvNyoaJyvW0VpNbLvfTSS/L19dWIESOUlZUlX1/f62774sWLV51I7XQ6XcsuWLBA58+f18CBAxUeHq6NGzfqtdde03//+18tWLDAtcw333yju+66Sz4+PhowYICqVq2q/fv365NPPtGECRPc1v+73/1OsbGxmjhxorZs2aJ//vOfioiI0N/+9rdCv36/tGnTJq1bt07du3dX5cqVdfDgQc2YMUP33HOPUlNTFRgY6DZ+8ODBCg0N1dixY5WWlqYZM2bo0KFDrrAm/Xw2KikpSYmJifrb3/6m8+fPa8aMGWrTpo22bt2qqlWrWtcN4DZkAOA2d/r0aSPJdO7cuUDjt23bZiSZfv36ubWPGDHCSDIrV650tUkyY8aMuWIdMTExJikpyfV81qxZRpJJSEgweXl5rvZhw4aZMmXKmIyMDFdbvXr1zN13333FOhs1amQ6duxYoH243LPPPmskmS+//NLVdubMGRMbG2uqVq1qcnNz3fZn0KBBhd7GtWq+nqttq6C1rlq1ykgy1apVM+fPny/w9q71+Ne//uUad7X1TZw40TgcDnPo0CFXW9u2bU3ZsmXd2owxbsd3zJgxRpL5/e9/7zbm4YcfNuHh4b9ac1JSkgkKCrrumKvVm5KSYiSZt99+29WW/zPYtGlTk52d7WqfNGmSkWQ++ugjY8zPr3doaKjp37+/2zrT09NNSEiIW3v+/gGAMcZwKRSA217+5TFly5Yt0PjFixdLkoYPH+7W/txzz0mS1VyMAQMGuF32c9dddyk3N1eHDh361WVDQ0O1a9cu7d27t1DbXLx4sZo3b642bdq42oKDgzVgwAAdPHhQqamphVpfcSpsrUlJSQoICCjw+jt37qxly5Zd8bj33ntdYy5f37lz5/TDDz+oVatWMsZo69atkqSTJ0/qiy++0O9//3tVqVLFbRtXu4Tsl3eduuuuu3Tq1KkiuXTr8npzcnJ06tQp1ahRQ6GhodqyZcsV4wcMGCAfHx/X84EDB8rb29v1c79s2TJlZGTo8ccf1w8//OB6lClTRi1atNCqVausawZwe+JSKAC3PafTKUk6c+ZMgcYfOnRIXl5eqlGjhlt7VFSUQkNDCxQCruWXH0LLlSsnSVe9xv2Xxo8fr86dO6tWrVqqX7++fvvb36pnz55q2LDhdZc7dOiQWrRocUV73bp1Xf03Mvm6OBS21tjY2EKtv3LlykpISLjumMOHD2v06NH6+OOPrzgup0+flvTzPBBJBX7drnfc838+b9SFCxc0ceJEzZo1S99//72MMVfUe7maNWu6PQ8ODlbFihVdczLyg+t999131e3Z1gvg9kWwAHDbczqdqlSpknbu3Fmo5Wy++Cs3N/eq7WXKlLlq++UfBq+lbdu22r9/vz766CMtXbpU//znPzVlyhS9/vrr6tev3w3XWpIV5mxFQeTm5qp9+/b68ccf9eKLL6pOnToKCgrS999/r969eysvL++G1mtz3H/NkCFDNGvWLD377LOKj49XSEiIHA6HunfvfkP15i8zd+5cRUVFXdHv7c1HBwBXx28HAKXCgw8+qJkzZyolJUXx8fHXHRsTE6O8vDzt3bvX9T/l0s8TizMyMhQTE+NqK1eunDIyMtyWz87O1rFjx2641usFmrCwMPXp00d9+vTR2bNn1bZtW40dO/a6wSImJkZpaWlXtO/Zs8fVf6vwdK07duzQt99+qzlz5rhNKv/lnbeqVasmSYUOq8Vh4cKFSkpK0iuvvOJqu3jx4hU/l/n27t3rdunX2bNndezYMT3wwAOSpOrVq0uSIiIifvXsDgBcjjkWAEqFF154QUFBQerXr5+OHz9+Rf/+/fs1bdo0SXJ9wJo6darbmMmTJ0uSOnbs6GqrXr26vvjiC7dxM2fOvOYZi4IICgq66ofCX34JXXBwsGrUqHHFLXB/6YEHHtDGjRuVkpLiajt37pxmzpypqlWrKi4u7oZrLWqerjX/zMLlZxKMMa6fjXwVKlRQ27Zt9dZbb+nw4cNufUVxFqIwypQpc8U2X3vttWv+DM6cOVM5OTmu5zNmzNClS5fUoUMHSVJiYqKcTqf+8pe/uI3Ld/ntkQHgcpyxAFAqVK9eXfPmzdNjjz2munXrun3z9rp167RgwQLX9040atRISUlJmjlzpjIyMnT33Xdr48aNmjNnjrp06eL2v739+vXTU089pa5du6p9+/bavn27Pv/8c5UvX/6Ga23atKlmzJihl19+WTVq1FBERITuu+8+xcXF6Z577lHTpk0VFhamr7/+WgsXLtTgwYOvu74//OEP+te//qUOHTpo6NChCgsL05w5c3TgwAG9//77N/RdFJL0xRdfuELVyZMnde7cOb388suSfr5sq23btoVeZ3HVmu/bb7/VO++8c0V7ZGSk2rdvrzp16qh69eoaMWKEvv/+ezmdTr3//vtXnQPz6quvqk2bNmrSpIkGDBig2NhYHTx4UJ9++qm2bdtmVeflcnJyXK/r5cLCwvT000/rwQcf1Ny5cxUSEqK4uDilpKRo+fLlCg8Pv+r6srOz1a5dO/3ud79TWlqapk+frjZt2uihhx6S9POlgzNmzFDPnj3VpEkTde/eXRUqVNDhw4f16aefqnXr1vrHP/5RZPsH4DbiuRtSAcDN9+2335r+/fubqlWrGl9fX1O2bFnTunVr89prr5mLFy+6xuXk5Jhx48aZ2NhY4+PjY6Kjo83IkSPdxhhjTG5urnnxxRdN+fLlTWBgoElMTDT79u275u1mN23a5LZ8/m1TV61a5WpLT083HTt2NGXLljWSXLdxffnll03z5s1NaGioCQgIMHXq1DETJkxwu3Xotezfv988+uijJjQ01Pj7+5vmzZubRYsWXTFOhbjdbP6tRq/2uNoteAu6rYLUmv+6LViwoEC15m/vWo/Lb5WbmppqEhISTHBwsClfvrzp37+/2b59u5FkZs2a5bbOnTt3mocffthVa+3atc2f//znK16jkydPui2X//Nw4MCB69aclJR0zZqrV69ujDHmp59+Mn369DHly5c3wcHBJjEx0ezZs+eaP4Nr1qwxAwYMMOXKlTPBwcGmR48e5tSpU1dse9WqVSYxMdGEhIQYf39/U716ddO7d2/z9ddfX7F/AGCMMQ5jbvI5WwAAAAC3HeZYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANb4gjxJeXl5Onr0qMqWLSuHw+HpcgAAAIBbgjFGZ86cUaVKlX71S0oJFpKOHj2q6OhoT5cBAAAA3JKOHDmiypUrX3cMwUJS2bJlJf38gjmdTg9XAwAAANwaMjMzFR0d7fq8fD0EC8l1+ZPT6SRYAAAAAL9QkOkCTN4GAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWvD1dAAAAtvbNWOPpEkqtGgPv9nQJAG4RnLEAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMCat6cLKKme++xtT5dQar3SoZenSwAAAMAvcMYCAAAAgDWCBQAAAABrBAsAAAAA1ggWAAAAAKwRLAAAAABYI1gAAAAAsEawAAAAAGCNYAEAAADAGsECAAAAgDWCBQAAAABrBAsAAAAA1ggWAAAAAKwRLAAAAABYI1gAAAAAsEawAAAAAGCNYAEAAADAGsECAAAAgDWCBQAAAABrBAsAAAAA1ggWAAAAAKwRLAAAAABYI1gAAAAAsEawAAAAAGCNYAEAAADAGsECAAAAgDWCBQAAAABrBAsAAAAA1ggWAAAAAKwRLAAAAABYI1gAAAAAsEawAAAAAGDNo8Fi7Nixcjgcbo86deq4+i9evKhBgwYpPDxcwcHB6tq1q44fP+62jsOHD6tjx44KDAxURESEnn/+eV26dOlm7woAAABQqnl7uoB69epp+fLlrufe3v9X0rBhw/Tpp59qwYIFCgkJ0eDBg/XII49o7dq1kqTc3Fx17NhRUVFRWrdunY4dO6ZevXrJx8dHf/nLX276vgAAAACllceDhbe3t6Kioq5oP336tN58803NmzdP9913nyRp1qxZqlu3rtavX6+WLVtq6dKlSk1N1fLlyxUZGanGjRvrpZde0osvvqixY8fK19f3Zu8OAAAAUCp5fI7F3r17ValSJVWrVk09evTQ4cOHJUmbN29WTk6OEhISXGPr1KmjKlWqKCUlRZKUkpKiBg0aKDIy0jUmMTFRmZmZ2rVr183dEQAAAKAU8+gZixYtWmj27NmqXbu2jh07pnHjxumuu+7Szp07lZ6eLl9fX4WGhrotExkZqfT0dElSenq6W6jI78/vu5asrCxlZWW5nmdmZhbRHgEAAAClk0eDRYcOHVz/btiwoVq0aKGYmBj9+9//VkBAQLFtd+LEiRo3blyxrR8AAAAobTx+KdTlQkNDVatWLe3bt09RUVHKzs5WRkaG25jjx4+75mRERUVdcZeo/OdXm7eRb+TIkTp9+rTrceTIkaLdEQAAAKCUuaWCxdmzZ7V//35VrFhRTZs2lY+Pj1asWOHqT0tL0+HDhxUfHy9Jio+P144dO3TixAnXmGXLlsnpdCouLu6a2/Hz85PT6XR7AAAAALhxHr0UasSIEerUqZNiYmJ09OhRjRkzRmXKlNHjjz+ukJAQ9e3bV8OHD1dYWJicTqeGDBmi+Ph4tWzZUpJ0//33Ky4uTj179tSkSZOUnp6uUaNGadCgQfLz8/PkrgEAAAClikeDxX//+189/vjjOnXqlCpUqKA2bdpo/fr1qlChgiRpypQp8vLyUteuXZWVlaXExERNnz7dtXyZMmW0aNEiDRw4UPHx8QoKClJSUpLGjx/vqV0CAAAASiWPBov58+dft9/f31/JyclKTk6+5piYmBgtXry4qEsDAAAAUAi31BwLAAAAACUTwQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFjz9nQBAAAA1zJ3wwBPl1Bq9Wwx09MloIThjAUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALB2ywSLv/71r3I4HHr22WddbRcvXtSgQYMUHh6u4OBgde3aVcePH3db7vDhw+rYsaMCAwMVERGh559/XpcuXbrJ1QMAAACl2y0RLDZt2qT//d//VcOGDd3ahw0bpk8++UQLFizQmjVrdPToUT3yyCOu/tzcXHXs2FHZ2dlat26d5syZo9mzZ2v06NE3excAAACAUs3jweLs2bPq0aOH3njjDZUrV87Vfvr0ab355puaPHmy7rvvPjVt2lSzZs3SunXrtH79eknS0qVLlZqaqnfeeUeNGzdWhw4d9NJLLyk5OVnZ2dme2iUAAACg1PF4sBg0aJA6duyohIQEt/bNmzcrJyfHrb1OnTqqUqWKUlJSJEkpKSlq0KCBIiMjXWMSExOVmZmpXbt23ZwdAAAAACBvT258/vz52rJlizZt2nRFX3p6unx9fRUaGurWHhkZqfT0dNeYy0NFfn9+37VkZWUpKyvL9TwzM/NGdwEAAACAPHjG4siRI3rmmWf07rvvyt/f/6Zue+LEiQoJCXE9oqOjb+r2AQAAgNuNx4LF5s2bdeLECTVp0kTe3t7y9vbWmjVr9Oqrr8rb21uRkZHKzs5WRkaG23LHjx9XVFSUJCkqKuqKu0TlP88fczUjR47U6dOnXY8jR44U7c4BAAAApYzHgkW7du20Y8cObdu2zfVo1qyZevTo4fq3j4+PVqxY4VomLS1Nhw8fVnx8vCQpPj5eO3bs0IkTJ1xjli1bJqfTqbi4uGtu28/PT06n0+0BAAAA4MZ5bI5F2bJlVb9+fbe2oKAghYeHu9r79u2r4cOHKywsTE6nU0OGDFF8fLxatmwpSbr//vsVFxennj17atKkSUpPT9eoUaM0aNAg+fn53fR9AgAAAEorj07e/jVTpkyRl5eXunbtqqysLCUmJmr69Omu/jJlymjRokUaOHCg4uPjFRQUpKSkJI0fP96DVQMAAAClzy0VLFavXu323N/fX8nJyUpOTr7mMjExMVq8eHExVwYAAADgejz+PRYAAAAASj6CBQAAAABrBAsAAAAA1ggWAAAAAKwRLAAAAABYI1gAAAAAsEawAAAAAGCNYAEAAADAGsECAAAAgDWCBQAAAABrBAsAAAAA1ggWAAAAAKwRLAAAAABYI1gAAAAAsEawAAAAAGCNYAEAAADAGsECAAAAgDWCBQAAAABrBAsAAAAA1ggWAAAAAKwRLAAAAABYI1gAAAAAsEawAAAAAGCNYAEAAADAGsECAAAAgDWCBQAAAABrBAsAAAAA1ggWAAAAAKwRLAAAAABYI1gAAAAAsEawAAAAAGCNYAEAAADAmrenCwAAAEDpc3TjA54uodSq1HxxsayXMxYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYK3IgsWlS5d0+PDholodAAAAgBKkyILFrl27FBsbW1SrAwAAAFCCcCkUAAAAAGveBR3YpEmT6/ZfuHDBuhgAKE7T3/nK0yWUWk8/0cbTJQAAilmBg0Vqaqq6d+9+zcudjh07pm+//bbICgMAAABQchQ4WNSvX18tWrTQwIEDr9q/bds2vfHGG0VWGAAAAICSo8BzLFq3bq20tLRr9pctW1Zt27YtkqIAAAAAlCwFPmMxbdq06/ZXr15dq1atsi4IAAAAQMnDXaEAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwFqBgsXHH3+snJyc4q4FAAAAQAlVoGDx8MMPKyMjQ5JUpkwZnThxojhrAgAAAFDCFChYVKhQQevXr5ckGWPkcDiKtSgAAAAAJUuBvsfiqaeeUufOneVwOORwOBQVFXXNsbm5uUVWHAAAAICSoUDBYuzYserevbv27dunhx56SLNmzVJoaGgxlwYAAACgpCjwN2/XqVNHderU0ZgxY9StWzcFBgYWZ10AAAAASpACB4t8Y8aMkSSdPHlSaWlpkqTatWurQoUKRVsZAAAAgBKj0N9jcf78ef3+979XpUqV1LZtW7Vt21aVKlVS3759df78+eKoEQAAAMAtrtDBYtiwYVqzZo0+/vhjZWRkKCMjQx999JHWrFmj5557rjhqBAAAAHCLK/SlUO+//74WLlyoe+65x9X2wAMPKCAgQL/73e80Y8aMoqwPAAAAQAlwQ5dCRUZGXtEeERHBpVAAAABAKVXoYBEfH68xY8bo4sWLrrYLFy5o3Lhxio+PL9S6ZsyYoYYNG8rpdMrpdCo+Pl6fffaZq//ixYsaNGiQwsPDFRwcrK5du+r48eNu6zh8+LA6duyowMBARURE6Pnnn9elS5cKu1sAAAAALBT6Uqhp06YpMTFRlStXVqNGjSRJ27dvl7+/vz7//PNCraty5cr661//qpo1a8oYozlz5qhz587aunWr6tWrp2HDhunTTz/VggULFBISosGDB+uRRx7R2rVrJf38ZXwdO3ZUVFSU1q1bp2PHjqlXr17y8fHRX/7yl8LuGgAAAIAbVOhgUb9+fe3du1fvvvuu9uzZI0l6/PHH1aNHDwUEBBRqXZ06dXJ7PmHCBM2YMUPr169X5cqV9eabb2revHm67777JEmzZs1S3bp1tX79erVs2VJLly5Vamqqli9frsjISDVu3FgvvfSSXnzxRY0dO1a+vr6F3T0AAAAAN6DQwUKSAgMD1b9//yItJDc3VwsWLNC5c+cUHx+vzZs3KycnRwkJCa4xderUUZUqVZSSkqKWLVsqJSVFDRo0cJvzkZiYqIEDB2rXrl264447rrqtrKwsZWVluZ5nZmYW6b4AAAAApU2h51gUtR07dig4OFh+fn566qmn9MEHHyguLk7p6eny9fVVaGio2/jIyEilp6dLktLT06+YSJ7/PH/M1UycOFEhISGuR3R0dNHuFAAAAFDKeDxY1K5dW9u2bdOGDRs0cOBAJSUlKTU1tVi3OXLkSJ0+fdr1OHLkSLFuDwAAALjd3dClUEXJ19dXNWrUkCQ1bdpUmzZt0rRp0/TYY48pOztbGRkZbmctjh8/rqioKElSVFSUNm7c6La+/LtG5Y+5Gj8/P/n5+RXxngAAAACll8fPWPxSXl6esrKy1LRpU/n4+GjFihWuvrS0NB0+fNh1W9v4+Hjt2LFDJ06ccI1ZtmyZnE6n4uLibnrtAAAAQGlV6DMW1apV06ZNmxQeHu7WnpGRoSZNmui7774r8LpGjhypDh06qEqVKjpz5ozmzZun1atX6/PPP1dISIj69u2r4cOHKywsTE6nU0OGDFF8fLxatmwpSbr//vsVFxennj17atKkSUpPT9eoUaM0aNAgzkgAAAAAN1Ghg8XBgweVm5t7RXtWVpa+//77Qq3rxIkT6tWrl44dO6aQkBA1bNhQn3/+udq3by9JmjJliry8vNS1a1dlZWUpMTFR06dPdy1fpkwZLVq0SAMHDlR8fLyCgoKUlJSk8ePHF3a3AAAAAFgocLD4+OOPXf/OP6OQLzc3VytWrFDVqlULtfE333zzuv3+/v5KTk5WcnLyNcfExMRo8eLFhdouAAAAgKJV4GDRpUsXSZLD4VBSUpJbn4+Pj6pWrapXXnmlSIsDAAAAUDIUOFjk5eVJkmJjY7Vp0yaVL1++2IoCAAAAULIUeo7FgQMHiqMOAAAAACXYDX2PxYoVK7RixQqdOHHCdSYj31tvvVUkhQEAAAAoOQodLMaNG6fx48erWbNmqlixohwOR3HUBQAAAKAEKXSweP311zV79mz17NmzOOoBAAAAUAIV+pu3s7Oz1apVq+KoBQAAAEAJVehg0a9fP82bN684agEAAABQQhX6UqiLFy9q5syZWr58uRo2bCgfHx+3/smTJxdZcQAAAABKhkIHi2+++UaNGzeWJO3cudOtj4ncAAAAQOlU6GCxatWq4qgDAAAAQAlW6DkWAAAAAPBLhT5jce+99173kqeVK1daFQQAAACg5Cl0sMifX5EvJydH27Zt086dO5WUlFRUdQEAAAAoQQodLKZMmXLV9rFjx+rs2bPWBQEAAAAoeYpsjsUTTzyht956q6hWBwAAAKAEKfQZi2tJSUmRv79/Ua0O8JgTM17wdAmlVsTASZ4uAQAA3KBCB4tHHnnE7bkxRseOHdPXX3+tP//5z0VWGAAAAICSo9DBIiQkxO25l5eXateurfHjx+v+++8vssIAAAAAlByFDhazZs0qjjoAAAAAlGA3PMdi8+bN2r17tySpXr16uuOOO4qsKAAAAAAlS6GDxYkTJ9S9e3etXr1aoaGhkqSMjAzde++9mj9/vipUqFDUNQIAAAC4xRX6drNDhgzRmTNntGvXLv3444/68ccftXPnTmVmZmro0KHFUSMAAACAW1yhz1gsWbJEy5cvV926dV1tcXFxSk5OZvI2AAAAUEoV+oxFXl6efHx8rmj38fFRXl5ekRQFAAAAoGQpdLC477779Mwzz+jo0aOutu+//17Dhg1Tu3btirQ4AAAAACVDoYPFP/7xD2VmZqpq1aqqXr26qlevrtjYWGVmZuq1114rjhoBAAAA3OIKPcciOjpaW7Zs0fLly7Vnzx5JUt26dZWQkFDkxQEAAAAoGW7oeywcDofat2+v9u3bF3U9AAAAAEqgAl8KtXLlSsXFxSkzM/OKvtOnT6tevXr68ssvi7Q4AAAAACVDgYPF1KlT1b9/fzmdziv6QkJC9OSTT2ry5MlFWhwAAACAkqHAwWL79u367W9/e83++++/X5s3by6SogAAAACULAUOFsePH7/q91fk8/b21smTJ4ukKAAAAAAlS4GDxW9+8xvt3Lnzmv3ffPONKlasWCRFAQAAAChZChwsHnjgAf35z3/WxYsXr+i7cOGCxowZowcffLBIiwMAAABQMhT4drOjRo3Sf/7zH9WqVUuDBw9W7dq1JUl79uxRcnKycnNz9ac//anYCgUAAABw6ypwsIiMjNS6des0cOBAjRw5UsYYST9/p0ViYqKSk5MVGRlZbIUCAAAAuHUV6gvyYmJitHjxYv3000/at2+fjDGqWbOmypUrV1z1AQAAACgBbuibt8uVK6c777yzqGsBAAAAUEIVePI2AAAAAFwLwQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWCBYAAAAArBEsAAAAAFgjWAAAAACwRrAAAAAAYI1gAQAAAMAawQIAAACANYIFAAAAAGsECwAAAADWPBosJk6cqDvvvFNly5ZVRESEunTporS0NLcxFy9e1KBBgxQeHq7g4GB17dpVx48fdxtz+PBhdezYUYGBgYqIiNDzzz+vS5cu3cxdAQAAAEo1jwaLNWvWaNCgQVq/fr2WLVumnJwc3X///Tp37pxrzLBhw/TJJ59owYIFWrNmjY4ePapHHnnE1Z+bm6uOHTsqOztb69at05w5czR79myNHj3aE7sEAAAAlErentz4kiVL3J7Pnj1bERER2rx5s9q2bavTp0/rzTff1Lx583TfffdJkmbNmqW6detq/fr1atmypZYuXarU1FQtX75ckZGRaty4sV566SW9+OKLGjt2rHx9fT2xawAAAECpckvNsTh9+rQkKSwsTJK0efNm5eTkKCEhwTWmTp06qlKlilJSUiRJKSkpatCggSIjI11jEhMTlZmZqV27dt3E6gEAAIDSy6NnLC6Xl5enZ599Vq1bt1b9+vUlSenp6fL19VVoaKjb2MjISKWnp7vGXB4q8vvz+64mKytLWVlZrueZmZlFtRsAAABAqXTLnLEYNGiQdu7cqfnz5xf7tiZOnKiQkBDXIzo6uti3CQAAANzObolgMXjwYC1atEirVq1S5cqVXe1RUVHKzs5WRkaG2/jjx48rKirKNeaXd4nKf54/5pdGjhyp06dPux5Hjhwpwr0BAAAASh+PBgtjjAYPHqwPPvhAK1euVGxsrFt/06ZN5ePjoxUrVrja0tLSdPjwYcXHx0uS4uPjtWPHDp04ccI1ZtmyZXI6nYqLi7vqdv38/OR0Ot0eAAAAAG6cR+dYDBo0SPPmzdNHH32ksmXLuuZEhISEKCAgQCEhIerbt6+GDx+usLAwOZ1ODRkyRPHx8WrZsqUk6f7771dcXJx69uypSZMmKT09XaNGjdKgQYPk5+fnyd0DAAAASg2PBosZM2ZIku655x639lmzZql3796SpClTpsjLy0tdu3ZVVlaWEhMTNX36dNfYMmXKaNGiRRo4cKDi4+MVFBSkpKQkjR8//mbtBgAAAFDqeTRYGGN+dYy/v7+Sk5OVnJx8zTExMTFavHhxUZYGAAAAoBBuicnbAAAAAEo2ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACseTRYfPHFF+rUqZMqVaokh8OhDz/80K3fGKPRo0erYsWKCggIUEJCgvbu3es25scff1SPHj3kdDoVGhqqvn376uzZszdxLwAAAAB4NFicO3dOjRo1UnJy8lX7J02apFdffVWvv/66NmzYoKCgICUmJurixYuuMT169NCuXbu0bNkyLVq0SF988YUGDBhws3YBAAAAgCRvT268Q4cO6tChw1X7jDGaOnWqRo0apc6dO0uS3n77bUVGRurDDz9U9+7dtXv3bi1ZskSbNm1Ss2bNJEmvvfaaHnjgAf39739XpUqVbtq+AAAAAKXZLTvH4sCBA0pPT1dCQoKrLSQkRC1atFBKSookKSUlRaGhoa5QIUkJCQny8vLShg0brrnurKwsZWZmuj0AAAAA3LhbNlikp6dLkiIjI93aIyMjXX3p6emKiIhw6/f29lZYWJhrzNVMnDhRISEhrkd0dHQRVw8AAACULrdssChOI0eO1OnTp12PI0eOeLokAAAAoES7ZYNFVFSUJOn48eNu7cePH3f1RUVF6cSJE279ly5d0o8//ugaczV+fn5yOp1uDwAAAAA37pYNFrGxsYqKitKKFStcbZmZmdqwYYPi4+MlSfHx8crIyNDmzZtdY1auXKm8vDy1aNHiptcMAAAAlFYevSvU2bNntW/fPtfzAwcOaNu2bQoLC1OVKlX07LPP6uWXX1bNmjUVGxurP//5z6pUqZK6dOkiSapbt65++9vfqn///nr99deVk5OjwYMHq3v37twRCgAAALiJPBosvv76a917772u58OHD5ckJSUlafbs2XrhhRd07tw5DRgwQBkZGWrTpo2WLFkif39/1zLvvvuuBg8erHbt2snLy0tdu3bVq6++etP3BQAAACjNPBos7rnnHhljrtnvcDg0fvx4jR8//ppjwsLCNG/evOIoDwAAAEAB3bJzLAAAAACUHAQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACs3TbBIjk5WVWrVpW/v79atGihjRs3erokAAAAoNS4LYLFe++9p+HDh2vMmDHasmWLGjVqpMTERJ04ccLTpQEAAAClwm0RLCZPnqz+/furT58+iouL0+uvv67AwEC99dZbni4NAAAAKBVKfLDIzs7W5s2blZCQ4Grz8vJSQkKCUlJSPFgZAAAAUHp4e7oAWz/88INyc3MVGRnp1h4ZGak9e/ZcdZmsrCxlZWW5np8+fVqSlJmZWeDtZp2/cAPVoigU5jjdiDMXsn59EIqFfzEf2wsXzhXr+nFtxf++5dh6SnEf2wvnsot1/bi2Yn/fns0p1vXj2gpzbPPHGmN+dWyJDxY3YuLEiRo3btwV7dHR0R6oBoWVrKc8XQKKy3OveroCFJMRAzxdAYrNc54uAMXlSc3xdAkoNiGFXuLMmTMKCbn+ciU+WJQvX15lypTR8ePH3dqPHz+uqKioqy4zcuRIDR8+3PU8Ly9PP/74o8LDw+VwOIq1Xk/LzMxUdHS0jhw5IqfT6elyUIQ4trcvju3ti2N7++LY3r5K27E1xujMmTOqVKnSr44t8cHC19dXTZs21YoVK9SlSxdJPweFFStWaPDgwVddxs/PT35+fm5toaGhxVzprcXpdJaKN0NpxLG9fXFsb18c29sXx/b2VZqO7a+dqchX4oOFJA0fPlxJSUlq1qyZmjdvrqlTp+rcuXPq06ePp0sDAAAASoXbIlg89thjOnnypEaPHq309HQ1btxYS5YsuWJCNwAAAIDicVsEC0kaPHjwNS99wv/x8/PTmDFjrrgUDCUfx/b2xbG9fXFsb18c29sXx/baHKYg944CAAAAgOso8V+QBwAAAMDzCBYAAAAArBEsgFvAPffco2effVaSVLVqVU2dOtWj9aD4GWM0YMAAhYWFyeFwaNu2bZ4uCcWkd+/ertuh4/bkcDj04YcferoM3GLGjh2rxo0be7qMm+q2mbwN3C42bdqkoKAgT5chSTp48KBiY2O1devWUvfLsbgtWbJEs2fP1urVq1WtWjWVL1/e0yWhmEybNk1MZwRKnxEjRmjIkCGeLuOmIljAWk5Ojnx8fDxdxm2jQoUKni4BN8H+/ftVsWJFtWrVqti2kZ2dLV9f32JbPwqmoF8sBeDWcqO/Q40xys3NVXBwsIKDg4uhslsXl0KVIEuWLFGbNm0UGhqq8PBwPfjgg9q/f7+kn/9n2eFw6D//+Y/uvfdeBQYGqlGjRkpJSXFbxxtvvKHo6GgFBgbq4Ycf1uTJk6/41vGPPvpITZo0kb+/v6pVq6Zx48bp0qVLrn6Hw6EZM2booYceUlBQkCZMmFDs+347OXfunHr16qXg4GBVrFhRr7zyilv/5ZdCGWM0duxYValSRX5+fqpUqZKGDh3qGnvs2DF17NhRAQEBio2N1bx589yWz/+5uPwym4yMDDkcDq1evVqS9NNPP6lHjx6qUKGCAgICVLNmTc2aNUuSFBsbK0m644475HA4dM899xTLa1La9O7dW0OGDNHhw4flcDhUtWpV5eXlaeLEiYqNjVVAQIAaNWqkhQsXupbJzc1V3759Xf21a9fWtGnTrlhvly5dNGHCBFWqVEm1a9e+2buGq7j8UqisrCwNHTpUERER8vf3V5s2bbRp0yZJP7/fa9Soob///e9uy2/btk0Oh0P79u272aXfthYuXKgGDRooICBA4eHhSkhI0Llz57Rp0ya1b99e5cuXV0hIiO6++25t2bLFbdm9e/eqbdu28vf3V1xcnJYtW+bWX9C/x1999ZXuuusuBQQEKDo6WkOHDtW5c+dc/dOnT1fNmjXl7++vyMhIPfroo79aP6792lx+yXG+Ll26qHfv3q7nVatW1UsvvaRevXrJ6XRqwIABruM5f/58tWrVSv7+/qpfv77WrFnjWm716tVyOBz67LPP1LRpU/n5+emrr7664lKo1atXq3nz5goKClJoaKhat26tQ4cOufp/7fNXiWBQYixcuNC8//77Zu/evWbr1q2mU6dOpkGDBiY3N9ccOHDASDJ16tQxixYtMmlpaebRRx81MTExJicnxxhjzFdffWW8vLzM//zP/5i0tDSTnJxswsLCTEhIiGsbX3zxhXE6nWb27Nlm//79ZunSpaZq1apm7NixrjGSTEREhHnrrbfM/v37zaFDh272S1GiDRw40FSpUsUsX77cfPPNN+bBBx80ZcuWNc8884wxxpiYmBgzZcoUY4wxCxYsME6n0yxevNgcOnTIbNiwwcycOdO1roSEBNO4cWOzfv16s3nzZnP33XebgIAA1/L5Pxdbt251LfPTTz8ZSWbVqlXGGGMGDRpkGjdubDZt2mQOHDhgli1bZj7++GNjjDEbN240kszy5cvNsWPHzKlTp4r75SkVMjIyzPjx403lypXNsWPHzIkTJ8zLL79s6tSpY5YsWWL2799vZs2aZfz8/Mzq1auNMcZkZ2eb0aNHm02bNpnvvvvOvPPOOyYwMNC89957rvUmJSWZ4OBg07NnT7Nz506zc+dOT+0iLpOUlGQ6d+5sjDFm6NChplKlSmbx4sVm165dJikpyZQrV8713powYYKJi4tzW37o0KGmbdu2N7vs29bRo0eNt7e3mTx5sjlw4ID55ptvTHJysjlz5oxZsWKFmTt3rtm9e7dJTU01ffv2NZGRkSYzM9MYY0xubq6pX7++adeundm2bZtZs2aNueOOO4wk88EHHxhjTIH+Hu/bt88EBQWZKVOmmG+//dasXbvW3HHHHaZ3797GGGM2bdpkypQpY+bNm2cOHjxotmzZYqZNm/ar9Zd213tt7r77btff2XydO3c2SUlJrucxMTHG6XSav//972bfvn1m3759ruNZuXJls3DhQpOammr69etnypYta3744QdjjDGrVq0ykkzDhg3N0qVLzb59+8ypU6fMmDFjTKNGjYwxxuTk5JiQkBAzYsQIs2/fPpOammpmz57t+gxVkM9fJQHBogQ7efKkkWR27Njh+sH/5z//6erftWuXkWR2795tjDHmscceMx07dnRbR48ePdyCRbt27cxf/vIXtzFz5841FStWdD2XZJ599tli2KPb35kzZ4yvr6/597//7Wo7deqUCQgIuGqweOWVV0ytWrVMdnb2FevavXu3kWQ2bdrkatu7d6+RVKhg0alTJ9OnT5+r1nu15VE0pkyZYmJiYowxxly8eNEEBgaadevWuY3p27evefzxx6+5jkGDBpmuXbu6niclJZnIyEiTlZVVLDXjxuQHi7NnzxofHx/z7rvvuvqys7NNpUqVzKRJk4wxxnz//femTJkyZsOGDa7+8uXLm9mzZ3uk9tvR5s2bjSRz8ODBXx2bm5trypYtaz755BNjjDGff/658fb2Nt9//71rzGeffXbVYHG9v8d9+/Y1AwYMcNvWl19+aby8vMyFCxfM+++/b5xOpyvQ3Gj9pc31XpuCBosuXbq4jck/nn/9619dbTk5OaZy5crmb3/7mzHm/4LFhx9+6Lbs5cHi1KlTRpLrP4t+qSCfv0oCLoUqQfbu3avHH39c1apVk9PpVNWqVSVJhw8fdo1p2LCh698VK1aUJJ04cUKSlJaWpubNm7ut85fPt2/frvHjx7uuCwwODlb//v117NgxnT9/3jWuWbNmRbpvpcX+/fuVnZ2tFi1auNrCwsKueclKt27ddOHCBVWrVk39+/fXBx984DotmpaWJm9vbzVp0sQ1vkaNGipXrlyhaho4cKDmz5+vxo0b64UXXtC6detuYM9gY9++fTp//rzat2/v9t57++23XZc7SlJycrKaNm2qChUqKDg4WDNnznR7/0tSgwYNmFdxi9q/f79ycnLUunVrV5uPj4+aN2+u3bt3S5IqVaqkjh076q233pIkffLJJ8rKylK3bt08UvPtqFGjRmrXrp0aNGigbt266Y033tBPP/0kSTp+/Lj69++vmjVrKiQkRE6nU2fPnnW9z3bv3q3o6GhVqlTJtb74+Pirbud6f4+3b9+u2bNnu73fExMTlZeXpwMHDqh9+/aKiYlRtWrV1LNnT7377ruuv8HXq7+0K4rX5lqfby4/zt7e3mrWrJnrfftry0o//63v3bu3EhMT1alTJ02bNk3Hjh1z9Rf089etjmBRgnTq1Ek//vij3njjDW3YsEEbNmyQ9PPkonyXT6J2OBySpLy8vAJv4+zZsxo3bpy2bdvmeuzYsUN79+6Vv7+/a9ytctei2110dLTS0tI0ffp0BQQE6Omnn1bbtm2Vk5NToOW9vH5+i5vL7kjzy2U7dOigQ4cOadiwYTp69KjatWunESNGFN1O4FedPXtWkvTpp5+6vfdSU1Nd8yzmz5+vESNGqG/fvlq6dKm2bdumPn36uL3/Jd6bt4N+/fpp/vz5unDhgmbNmqXHHntMgYGBni7rtlGmTBktW7ZMn332meLi4vTaa6+pdu3aOnDggJKSkrRt2zZNmzZN69at07Zt2xQeHn7F+6wgrvf3+OzZs3ryySfd3u/bt2/X3r17Vb16dZUtW1ZbtmzRv/71L1WsWFGjR49Wo0aNlJGRcd36S7vrvTZeXl5X3J3tan9LbX6H/tqys2bNUkpKilq1aqX33ntPtWrV0vr16yUV/PPXrY5gUUKcOnVKaWlpGjVqlNq1a6e6desWOoXXrl3bNUkw3y+fN2nSRGlpaapRo8YVj/wPqbhx1atXl4+PjysUSj9Pnv7222+vuUxAQIA6deqkV199VatXr1ZKSop27Nih2rVr69KlS9q6datr7L59+9x+LvLvMHX5/4pc7fsSKlSooKSkJL3zzjuaOnWqZs6cKUmu//nOzc29sR1GgcTFxcnPz0+HDx++4n0XHR0tSVq7dq1atWqlp59+WnfccYdq1KjhdjYDt77q1avL19dXa9eudbXl5ORo06ZNiouLc7U98MADCgoK0owZM7RkyRL9/ve/90S5tzWHw6HWrVtr3Lhx2rp1q3x9ffXBBx9o7dq1Gjp0qB544AHVq1dPfn5++uGHH1zL1a1bV0eOHHH7nZr/wbAwmjRpotTU1Kv+rc3/vevt7a2EhARNmjRJ33zzjQ4ePKiVK1det35c+7WpUKGC23HLzc3Vzp07C7zey4/zpUuXtHnzZtWtW7fQ9d1xxx0aOXKk1q1bp/r162vevHmSbp/PX9xutoQoV66cwsPDNXPmTFWsWFGHDx/WH/7wh0KtY8iQIWrbtq0mT56sTp06aeXKlfrss89c/5MiSaNHj9aDDz6oKlWq6NFHH5WXl5e2b9+unTt36uWXXy7q3Sp1goOD1bdvXz3//PMKDw9XRESE/vSnP13zl8bs2bOVm5urFi1aKDAwUO+8844CAgIUExPjutvFgAEDNGPGDPn4+Oi5555TQECA65gGBASoZcuW+utf/6rY2FidOHFCo0aNctvG6NGj1bRpU9WrV09ZWVlatGiR65dlRESEAgICtGTJElWuXFn+/v7cOrMYlC1bViNGjNCwYcOUl5enNm3a6PTp01q7dq2cTqeSkpJUs2ZNvf322/r8888VGxuruXPnatOmTa47d+HWFxQUpIEDB+r5559XWFiYqlSpokmTJun8+fPq27eva1yZMmXUu3dvjRw5UjVr1rzmpTa4MRs2bNCKFSt0//33KyIiQhs2bNDJkydVt25d1axZU3PnzlWzZs2UmZmp559/XgEBAa5lExISVKtWLSUlJel//ud/lJmZqT/96U+FruHFF19Uy5YtNXjwYPXr109BQUFKTU3VsmXL9I9//EOLFi3Sd999p7Zt26pcuXJavHix8vLyVLt27evWX9pd77UJCgrS8OHD9emnn6p69eqaPHmyMjIyCrzu5ORk1axZU3Xr1tWUKVP0008/FSr0HzhwQDNnztRDDz2kSpUqKS0tTXv37lWvXr0k3Uafvzw9yQMFt2zZMlO3bl3j5+dnGjZsaFavXu2aMFaQSbrGGDNz5kzzm9/8xgQEBJguXbqYl19+2URFRbltZ8mSJaZVq1YmICDAOJ1O07x5c7c7EemySWoovDNnzpgnnnjCBAYGmsjISDNp0iS3SWWXT97+4IMPTIsWLYzT6TRBQUGmZcuWZvny5a51HT161HTo0MH4+fmZmJgYM2/ePBMREWFef/1115jU1FQTHx9vAgICTOPGjc3SpUvdfi5eeuklU7duXRMQEGDCwsJM586dzXfffeda/o033jDR0dHGy8vL3H333cX98pQal0/eNsaYvLw8M3XqVFO7dm3j4+NjKlSoYBITE82aNWuMMT9P8O7du7cJCQkxoaGhZuDAgeYPf/iDa2KgMe53H8Kt4/LjcuHCBTNkyBBTvnx54+fnZ1q3bm02btx4xTL79+83klyTulF0UlNTTWJioqlQoYLx8/MztWrVMq+99poxxpgtW7aYZs2aGX9/f1OzZk2zYMECt9/JxhiTlpZm2rRpY3x9fU2tWrXMkiVLrjp5+9f+Hm/cuNG0b9/eBAcHm6CgINOwYUMzYcIEY8zPE7nvvvtuU65cORMQEGAaNmzougPc9eov7a732mRnZ5uBAweasLAwExERYSZOnHjVyduXH2tj/u94zps3zzRv3tz4+vqauLg4s3LlSteY/MnbP/30k9uyl0/eTk9PN126dDEVK1Y0vr6+JiYmxowePdrk5ua6xv/a56+SwGEMXwdamvXv31979uzRl19+6elSUAT++9//Kjo6WsuXL1e7du08XQ4ASY8//rjKlCmjd955p8DLfPnll2rXrp2OHDmiyMjIYqwOwPUcPHhQsbGx2rp1q9t3UuDquBSqlPn73/+u9u3bKygoSJ999pnmzJmj6dOne7os3KCVK1fq7NmzatCggY4dO6YXXnhBVatWVdu2bT1dGlDqXbp0Sd9++61SUlL05JNPFmiZrKwsnTx5UmPHjlW3bt0IFQBKlJIzGwRFYuPGjWrfvr0aNGig119/Xa+++qr69evn6bJwg3JycvTHP/5R9erV08MPP6wKFSpo9erVbncjAeAZO3fuVLNmzVSvXj099dRTBVrmX//6l2JiYpSRkaFJkyYVc4UAULS4FAoAAACANc5YAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAMAtYfbs2QoNDbVej8Ph0Icffmi9HgBA4RAsAABFpnfv3urSpYunywAAeADBAgAAAIA1ggUA4KaYPHmyGjRooKCgIEVHR+vpp5/W2bNnrxj34YcfqmbNmvL391diYqKOHDni1v/RRx+pSZMm8vf3V7Vq1TRu3DhdunTpZu0GAOAaCBYAgJvCy8tLr776qnbt2qU5c+Zo5cqVeuGFF9zGnD9/XhMmTNDbb7+ttWvXKiMjQ927d3f1f/nll+rVq5eeeeYZpaam6n//9381e/ZsTZgw4WbvDgDgFxzGGOPpIgAAt4fevXsrIyOjQJOnFy5cqKeeeko//PCDpJ8nb/fp00fr169XixYtJEl79uxR3bp1tWHDBjVv3lwJCQlq166dRo4c6VrPO++8oxdeeEFHjx6V9PPk7Q8++IC5HgBwk3l7ugAAQOmwfPlyTZw4UXv27FFmZqYuXbqkixcv6vz58woMDJQkeXt7684773QtU6dOHYWGhmr37t1q3ry5tm/frrVr17qdocjNzb1iPQCAm49gAQAodgcPHtSDDz6ogQMHasKECQoLC9NXX32lvn37Kjs7u8CB4OzZsxo3bpweeeSRK/r8/f2LumwAQCEQLAAAxW7z5s3Ky8vTK6+8Ii+vn6f3/fvf/75i3KVLl/T111+refPmkqS0tDRlZGSobt26kqQmTZooLS1NNWrUuHnFAwAKhGABAChSp0+f1rZt29zaypcvr5ycHL322mvq1KmT1q5dq9dff/2KZX18fDRkyBC9+uqr8vb21uDBg9WyZUtX0Bg9erQefPBBValSRY8++qi8vLy0fft27dy5Uy+//PLN2D0AwDVwVygAQJFavXq17rjjDrfH3LlzNXnyZP3tb39T/fr19e6772rixIlXLBsYGKgXX3xR/+///T+1bt1awcHBeu+991z9iYmJWrRokZYuXao777xTLVu21JQpUxQTE3MzdxEAcBXcFQoAAACANc5YAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIA1ggUAAAAAawQLAAAAANYIFgAAAACsESwAAAAAWCNYAAAAALBGsAAAAABgjWABAAAAwBrBAgAAAIC1/w93cYjgHNtOWgAAAABJRU5ErkJggg==\n"},"metadata":{}}],"execution_count":88},{"cell_type":"code","source":"# 4. Extract Text Embeddings (Same logic, but shorten max_length if needed)\n# -------------------------------------------------------\ndef extract_text_embeddings(df, save_path, model, tokenizer):\n    if os.path.exists(save_path):\n        print(f\"Embeddings already exist at {save_path}\")\n        return torch.load(save_path)\n\n    embeddings = {}\n    model.eval()\n    with torch.no_grad():\n        for idx, row in tqdm(df.iterrows(), desc=\"Extracting text embeddings\", total=len(df)):\n            text_sample = row[TEXT_VAR]\n            text_sample = text_sample if isinstance(text_sample, str) else \"\"\n\n            inputs = tokenizer(\n                text_sample,\n                padding=\"max_length\",\n                truncation=True,\n                max_length=128,\n                return_tensors=\"pt\"\n            ).to(device)\n\n            outputs = model(**inputs)\n            cls_embedding = outputs.last_hidden_state[:, 0, :]\n            embeddings[idx] = cls_embedding.cpu()\n\n    torch.save(embeddings, save_path)\n    return embeddings\n\ntrain_text_embeddings = extract_text_embeddings(train_df, \"train_text_embeddings.pt\", text_model, text_tokenizer)\nval_text_embeddings   = extract_text_embeddings(val_df,   \"val_text_embeddings.pt\",   text_model, text_tokenizer)\ntest_text_embeddings  = extract_text_embeddings(test_df,  \"test_text_embeddings.pt\",  text_model, text_tokenizer)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2bTxzSgPR7Ss","outputId":"a5015b79-4eba-4ab8-d213-1c3e93c82e0d","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:06.391334Z","iopub.execute_input":"2025-01-29T18:31:06.391565Z","iopub.status.idle":"2025-01-29T18:31:06.567026Z","shell.execute_reply.started":"2025-01-29T18:31:06.391545Z","shell.execute_reply":"2025-01-29T18:31:06.566232Z"}},"outputs":[{"name":"stdout","text":"Embeddings already exist at train_text_embeddings.pt\nEmbeddings already exist at val_text_embeddings.pt\nEmbeddings already exist at test_text_embeddings.pt\n","output_type":"stream"}],"execution_count":89},{"cell_type":"code","source":"# 5. Prepare Embeddings (CHANGED for Multi‐Label)\n# -------------------------------------------------------\ndef prepare_text_embeddings(text_embeddings, df, label_cols=None, has_labels=True):\n    \"\"\"\n    For each row in df, gather the text embedding and (optionally) the labels.\n    label_cols: list of columns for multi-label (e.g. [\"anger\", \"fear\", \"joy\", ...])\n    \"\"\"\n    combined_embeddings = []\n    labels = []\n\n    for idx, row in df.iterrows():\n        if idx not in text_embeddings:\n            continue\n        # Get the [CLS] embedding\n        text_embedding = text_embeddings[idx].squeeze()  # shape: (768,)\n        combined_embeddings.append(text_embedding)\n\n        if has_labels and label_cols is not None:\n            # Collect all label columns as a float vector\n            label_vector = row[label_cols].values.astype(float)  # shape: (5,)\n            labels.append(label_vector)\n\n    # Convert to Tensors\n    if has_labels and label_cols is not None:\n        X = torch.stack(combined_embeddings)\n        Y = torch.tensor(labels, dtype=torch.float)  # multi-label => float\n        return X, Y\n    else:\n        return torch.stack(combined_embeddings)\n\nX_train, y_train = prepare_text_embeddings(train_text_embeddings, train_df, LABEL_COLS, has_labels=True)\nX_val,   y_val   = prepare_text_embeddings(val_text_embeddings,   val_df,   LABEL_COLS, has_labels=True)\nX_test           = prepare_text_embeddings(test_text_embeddings,  test_df,  LABEL_COLS, has_labels=False)\n\nprint(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\nprint(\"X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\nprint(\"X_test: \", X_test.shape)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ykURmiwuSCBQ","outputId":"aef3bcf9-a5c1-441a-ef65-8af4f9314d18","execution":{"iopub.status.busy":"2025-01-29T18:31:06.568723Z","iopub.execute_input":"2025-01-29T18:31:06.568992Z","iopub.status.idle":"2025-01-29T18:31:07.654918Z","shell.execute_reply.started":"2025-01-29T18:31:06.568960Z","shell.execute_reply":"2025-01-29T18:31:07.654137Z"},"trusted":true},"outputs":[{"name":"stdout","text":"X_train: torch.Size([2679, 768]) y_train: torch.Size([2679, 6])\nX_val:   torch.Size([199, 768]) y_val:   torch.Size([199, 6])\nX_test:  torch.Size([1000, 768])\n","output_type":"stream"}],"execution_count":90},{"cell_type":"markdown","source":"\ndef balance_multilabel_data(X, Y):\n    \"\"\"\n    Oversample minority label-combinations in a multi-label setting.\n    1. Convert each row's label vector (like [1,0,1,0,0]) into a tuple (1.0,0.0,1.0,0.0,0.0).\n    2. Count how many rows share that exact tuple (i.e., label combination).\n    3. Duplicate those rows until they match the frequency of the most common combination.\n\n    NOTE: This lumps each distinct 5-label pattern as one \"class.\"\n    If every row has a unique pattern, this won't help much.\n    \"\"\"\n    from collections import Counter\n\n    # Convert each label row to a tuple\n    label_tuples = [tuple(row.tolist()) for row in Y]\n    class_counts = Counter(label_tuples)\n    max_count = max(class_counts.values())\n\n    # We'll store duplicates in lists, then convert to tensors\n    balanced_embeddings = []\n    balanced_labels = []\n\n    for i, label_tuple in enumerate(label_tuples):\n        balanced_embeddings.append(X[i])\n        balanced_labels.append(label_tuple)\n\n        current_count = class_counts[label_tuple]\n        # e.g., duplicates_needed = how many times to replicate?\n        duplicates_needed = int((max_count - current_count) / current_count)\n\n        for _ in range(duplicates_needed):\n            balanced_embeddings.append(X[i])\n            balanced_labels.append(label_tuple)\n\n    balanced_embeddings = torch.stack(balanced_embeddings)\n    balanced_labels = torch.tensor(balanced_labels, dtype=torch.float)\n    print(f\"Original dataset size: {X.shape[0]}\")\n    print(f\"Balanced dataset size: {balanced_embeddings.shape[0]}\")\n    return balanced_embeddings, balanced_labels\n\n# Call our new multi-label balancing function\nX_train, y_train = balance_multilabel_data(X_train, y_train)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7oz_zljhMpnm","outputId":"8831f5e6-7127-4836-80ee-2a3b1f0ae663","execution":{"iopub.status.busy":"2025-01-29T18:30:38.403230Z","iopub.execute_input":"2025-01-29T18:30:38.403563Z","iopub.status.idle":"2025-01-29T18:30:38.481106Z","shell.execute_reply.started":"2025-01-29T18:30:38.403531Z","shell.execute_reply":"2025-01-29T18:30:38.480320Z"}}},{"cell_type":"code","source":"# 6. Define Multi‐Label MLP Model (CHANGED)\n# -------------------------------------------------------\nclass MLPModel(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim, dropout_p=0.5):\n        super(MLPModel, self).__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n        self.relu = nn.ReLU()\n        self.dropout1 = nn.Dropout(p=dropout_p)\n        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n        self.dropout2 = nn.Dropout(p=dropout_p)\n        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n        # For multi‐label, we *do not* apply softmax, we will use BCEWithLogitsLoss\n\n    def forward(self, x):\n        x = self.relu(self.fc1(x))\n        x = self.dropout1(x)\n        x = self.relu(self.fc2(x))\n        x = self.dropout2(x)\n        x = self.fc3(x)            # shape: (batch_size, 5)\n        # No softmax here for multi‐label. Return raw logits for BCEWithLogitsLoss\n        return x\n","metadata":{"id":"j2JzYjEHSMu7","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:07.655713Z","iopub.execute_input":"2025-01-29T18:31:07.655925Z","iopub.status.idle":"2025-01-29T18:31:07.661454Z","shell.execute_reply.started":"2025-01-29T18:31:07.655903Z","shell.execute_reply":"2025-01-29T18:31:07.660629Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"# Model & Hyperparams\ninput_dim    = X_train.shape[1]        # e.g. 768\nhidden_dim   = [786, 512]             # can be tuned\noutput_dim   = len(LABEL_COLS)        # 5 for multi‐label\ndropout_p    = 0.3\nnum_epochs   = 10\nbatch_size   = 16\nlearning_rate = 1e-4\n\nmodel = MLPModel(input_dim, hidden_dim, output_dim, dropout_p).to(device)","metadata":{"id":"TSkqLDOVSVyh","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:07.662349Z","iopub.execute_input":"2025-01-29T18:31:07.662645Z","iopub.status.idle":"2025-01-29T18:31:07.685296Z","shell.execute_reply.started":"2025-01-29T18:31:07.662615Z","shell.execute_reply":"2025-01-29T18:31:07.684585Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"# 7. CHANGED: Use BCEWithLogitsLoss (for multi‐label)\n# -------------------------------------------------------\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"id":"qeMpwVS2SYam","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:07.686237Z","iopub.execute_input":"2025-01-29T18:31:07.686539Z","iopub.status.idle":"2025-01-29T18:31:07.690817Z","shell.execute_reply.started":"2025-01-29T18:31:07.686507Z","shell.execute_reply":"2025-01-29T18:31:07.690073Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"# 8. Dataloaders\n# -------------------------------------------------------\ntrain_dataset = TensorDataset(X_train, y_train)\nval_dataset   = TensorDataset(X_val,   y_val)\ntest_dataset  = TensorDataset(X_test)  # no labels for test\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader   = DataLoader(val_dataset,   batch_size=batch_size)\ntest_loader  = DataLoader(test_dataset,  batch_size=batch_size)","metadata":{"id":"RIiqLiirSbo5","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:07.691659Z","iopub.execute_input":"2025-01-29T18:31:07.691921Z","iopub.status.idle":"2025-01-29T18:31:07.704520Z","shell.execute_reply.started":"2025-01-29T18:31:07.691891Z","shell.execute_reply":"2025-01-29T18:31:07.703800Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"# 9. Metrics for Multi‐Label (CHANGED)\n# -------------------------------------------------------\ndef calculate_metrics(preds, labels):\n    \"\"\"\n    preds, labels are lists (or arrays) of shape (N, 5).\n    We'll do an example with macro avg for PRF.\n    \"\"\"\n    preds = np.array(preds)\n    labels = np.array(labels)\n\n    # Example: For each label, threshold at 0.5\n    # (We already do that during loop, but let's be explicit.)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        labels, preds, average='macro', zero_division=0\n    )\n    # Multi‐label “accuracy” can be ambiguous.\n    # Some do “exact match ratio”, etc. We'll do a simple overall average:\n    accuracy = (preds == labels).mean()\n\n    return accuracy, precision, recall, f1","metadata":{"id":"7biPQklUSeXM","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:07.705528Z","iopub.execute_input":"2025-01-29T18:31:07.705806Z","iopub.status.idle":"2025-01-29T18:31:07.710168Z","shell.execute_reply.started":"2025-01-29T18:31:07.705778Z","shell.execute_reply":"2025-01-29T18:31:07.709371Z"}},"outputs":[],"execution_count":95},{"cell_type":"code","source":"# 10. Train and Validate (CHANGES in Predictions)\n# -------------------------------------------------------\ndef train_and_save_best_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, save_dir):\n    best_f1 = -float('inf')\n    best_model_path = None\n\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0\n        all_train_preds, all_train_labels = [], []\n\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)  # shape: (batch_size, 5)\n            # For BCEWithLogitsLoss, labels should be float\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n\n            # Convert logits -> probabilities -> binary predictions\n            preds = (torch.sigmoid(outputs) > 0.5).float()\n            all_train_preds.extend(preds.cpu().tolist())\n            all_train_labels.extend(labels.cpu().tolist())\n\n        # Training metrics\n        train_accuracy, train_precision, train_recall, train_f1 = calculate_metrics(all_train_preds, all_train_labels)\n\n        # Validation\n        model.eval()\n        val_loss = 0\n        all_val_preds, all_val_labels = [], []\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)  # shape: (batch_size, 5)\n\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n\n                preds = (torch.sigmoid(outputs) > 0.5).float()\n                all_val_preds.extend(preds.cpu().tolist())\n                all_val_labels.extend(labels.cpu().tolist())\n\n        val_accuracy, val_precision, val_recall, val_f1 = calculate_metrics(all_val_preds, all_val_labels)\n\n        print(\n            f\"Epoch {epoch+1}/{num_epochs} \"\n            f\"Train Loss: {train_loss/len(train_loader):.4f}, \"\n            f\"Train Acc: {train_accuracy:.4f}, F1: {train_f1:.4f} | \"\n            f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n            f\"Val Acc: {val_accuracy:.4f}, F1: {val_f1:.4f}\"\n        )\n\n        # Save best model by val_f1\n        if val_f1 > best_f1:\n            best_f1 = val_f1\n            best_model_path = os.path.join(save_dir, f\"best_model_epoch_{epoch+1}_f1_{val_f1:.4f}.pth\")\n            torch.save(model.state_dict(), best_model_path)\n            print(f\"Best model saved with F1: {val_f1:.4f} at epoch {epoch+1}\")\n\n    return best_model_path\n\nsave_dir = \"./models\"\nos.makedirs(save_dir, exist_ok=True)\n\nbest_model_path = train_and_save_best_model(\n    model, train_loader, val_loader, criterion, optimizer, num_epochs, save_dir\n)\n\nprint(f\"Best model saved at: {best_model_path}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AHid0LPJShaz","outputId":"3e765570-2ac8-45c2-8534-e782233435b9","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:07.711006Z","iopub.execute_input":"2025-01-29T18:31:07.711310Z","iopub.status.idle":"2025-01-29T18:31:11.605077Z","shell.execute_reply.started":"2025-01-29T18:31:07.711280Z","shell.execute_reply":"2025-01-29T18:31:11.604251Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10 Train Loss: 0.2677, Train Acc: 0.9020, F1: 0.5767 | Val Loss: 0.1491, Val Acc: 0.9489, F1: 0.8351\nBest model saved with F1: 0.8351 at epoch 1\nEpoch 2/10 Train Loss: 0.1531, Train Acc: 0.9433, F1: 0.8001 | Val Loss: 0.1407, Val Acc: 0.9489, F1: 0.8321\nEpoch 3/10 Train Loss: 0.1446, Train Acc: 0.9465, F1: 0.8114 | Val Loss: 0.1379, Val Acc: 0.9497, F1: 0.8359\nBest model saved with F1: 0.8359 at epoch 3\nEpoch 4/10 Train Loss: 0.1388, Train Acc: 0.9486, F1: 0.8197 | Val Loss: 0.1402, Val Acc: 0.9464, F1: 0.8270\nEpoch 5/10 Train Loss: 0.1361, Train Acc: 0.9492, F1: 0.8222 | Val Loss: 0.1351, Val Acc: 0.9523, F1: 0.8439\nBest model saved with F1: 0.8439 at epoch 5\nEpoch 6/10 Train Loss: 0.1318, Train Acc: 0.9509, F1: 0.8281 | Val Loss: 0.1335, Val Acc: 0.9531, F1: 0.8440\nBest model saved with F1: 0.8440 at epoch 6\nEpoch 7/10 Train Loss: 0.1281, Train Acc: 0.9537, F1: 0.8373 | Val Loss: 0.1304, Val Acc: 0.9548, F1: 0.8517\nBest model saved with F1: 0.8517 at epoch 7\nEpoch 8/10 Train Loss: 0.1224, Train Acc: 0.9556, F1: 0.8438 | Val Loss: 0.1335, Val Acc: 0.9581, F1: 0.8635\nBest model saved with F1: 0.8635 at epoch 8\nEpoch 9/10 Train Loss: 0.1217, Train Acc: 0.9561, F1: 0.8455 | Val Loss: 0.1329, Val Acc: 0.9539, F1: 0.8457\nEpoch 10/10 Train Loss: 0.1165, Train Acc: 0.9577, F1: 0.8498 | Val Loss: 0.1291, Val Acc: 0.9573, F1: 0.8616\nBest model saved at: ./models/best_model_epoch_8_f1_0.8635.pth\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"# 11. Test Predictions (CHANGES for Multi‐Label)\n# -------------------------------------------------------\ndef predict_and_generate_submission(test_loader, best_model_path, submission_file_path):\n    # Reload a fresh model\n    inference_model = MLPModel(input_dim, hidden_dim, output_dim, dropout_p).to(device)\n    inference_model.load_state_dict(torch.load(best_model_path))\n    inference_model.eval()\n\n    # We'll store multi‐label predictions as 0/1 for each label\n    test_predictions = []\n    with torch.no_grad():\n        for (inputs,) in test_loader:  # Each batch is a tuple containing only X\n            inputs = inputs.to(device)\n            outputs = inference_model(inputs)\n            preds = (torch.sigmoid(outputs) > 0.5).int()  # shape: (batch_size, 5)\n            test_predictions.append(preds.cpu())\n\n    test_predictions = torch.cat(test_predictions, dim=0).numpy()  # shape: (num_samples, 5)\n\n    # Build submission DataFrame\n    submission_df = pd.DataFrame({\n        \"id\": test_df[\"id\"],  # or whatever your ID is\n        \"anger_pred\":    test_predictions[:, 0],\n        \"disgust_pred\":  test_predictions[:, 1],\n        \"fear_pred\":     test_predictions[:, 2],\n        \"joy_pred\":      test_predictions[:, 3],\n        \"sadness_pred\": test_predictions[:, 4],\n        \"surprise_pred\":test_predictions[:, 5]\n    })\n\n    submission_df.to_csv(submission_file_path, index=False)\n    print(f\"Submission file saved to {submission_file_path}\")\n    return submission_df\n\nsubmission_file_path = \"submission.csv\"\nsubmission_df = predict_and_generate_submission(test_loader, best_model_path, submission_file_path)\nsubmission_df.head()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"id":"kvMYTGpMSmf9","outputId":"8785d5d4-4b92-4e8d-f869-5fd273b2fff4","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T18:31:11.605931Z","iopub.execute_input":"2025-01-29T18:31:11.606206Z","iopub.status.idle":"2025-01-29T18:31:11.666010Z","shell.execute_reply.started":"2025-01-29T18:31:11.606184Z","shell.execute_reply":"2025-01-29T18:31:11.665357Z"}},"outputs":[{"name":"stdout","text":"Submission file saved to submission.csv\n","output_type":"stream"},{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"                       id  anger_pred  disgust_pred  fear_pred  joy_pred  \\\n0  rus_test_track_a_00001           0             0          1         0   \n1  rus_test_track_a_00002           0             0          0         0   \n2  rus_test_track_a_00003           1             0          0         0   \n3  rus_test_track_a_00004           1             0          0         0   \n4  rus_test_track_a_00005           0             0          0         1   \n\n   sadness_pred  surprise_pred  \n0             0              0  \n1             0              0  \n2             0              0  \n3             0              0  \n4             0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>anger_pred</th>\n      <th>disgust_pred</th>\n      <th>fear_pred</th>\n      <th>joy_pred</th>\n      <th>sadness_pred</th>\n      <th>surprise_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>rus_test_track_a_00001</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rus_test_track_a_00002</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>rus_test_track_a_00003</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>rus_test_track_a_00004</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>rus_test_track_a_00005</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":97},{"cell_type":"code","source":"","metadata":{"id":"Tla8NpESSvNV","trusted":true},"outputs":[],"execution_count":null}]}
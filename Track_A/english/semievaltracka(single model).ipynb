{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "KI3yCJWMQ5WD"
      },
      "outputs": [],
      "source": [
        "# 1. Imports & Setup (Same as before)\n",
        "# -------------------------------------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from tqdm import tqdm\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX8gy3z6RS6b",
        "outputId": "69de4dce-fd93-4fe8-b604-bcc8d2fe76a8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd08a522d30>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = \"/content/eng.csv\"\n",
        "VAL_PATH   = \"/content/engdev.csv\"\n",
        "TEST_PATH  = \"/content/engtest.csv\"\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "val_df   = pd.read_csv(VAL_PATH)\n",
        "test_df  = pd.read_csv(TEST_PATH)\n"
      ],
      "metadata": {
        "id": "pT_l4ECRRbKN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instead of a single LABEL_VAR, define multiple label columns:\n",
        "LABEL_COLS = [\"anger\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
        "TEXT_VAR   = \"text\""
      ],
      "metadata": {
        "id": "rDWDRDJ5Renf"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Load Tokenizer & Model for Embedding Extraction\n",
        "# -------------------------------------------------------\n",
        "model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
        "text_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "text_model = AutoModel.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8u8RiC5Rg9Z",
        "outputId": "7cb689e0-763e-466f-8031-e7e02b69cf59"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at j-hartmann/emotion-english-distilroberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect the counts of \"1\" for each label\n",
        "counts_ones = []\n",
        "for label in LABEL_COLS:\n",
        "    # Count how many rows in train_df have this label = 1\n",
        "    num_ones = (train_df[label] == 1).sum()\n",
        "    counts_ones.append((label, num_ones))\n",
        "\n",
        "# Build a DataFrame for plotting\n",
        "counts_df = pd.DataFrame(counts_ones, columns=[\"label\", \"count_of_1\"])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(\n",
        "    x=\"label\",\n",
        "    y=\"count_of_1\",\n",
        "    data=counts_df,\n",
        "    palette=\"Set2\"\n",
        ")\n",
        "plt.title(\"Counts of 1 for Each Label\")\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"Count of 1\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "GMKGxX6iKo49",
        "outputId": "af54ff1b-66a8-4357-d142-9bb154f2fc39"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Extract Text Embeddings (Same logic, but shorten max_length if needed)\n",
        "# -------------------------------------------------------\n",
        "def extract_text_embeddings(df, save_path, model, tokenizer):\n",
        "    if os.path.exists(save_path):\n",
        "        print(f\"Embeddings already exist at {save_path}\")\n",
        "        return torch.load(save_path)\n",
        "\n",
        "    embeddings = {}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx, row in tqdm(df.iterrows(), desc=\"Extracting text embeddings\", total=len(df)):\n",
        "            text_sample = row[TEXT_VAR]\n",
        "            text_sample = text_sample if isinstance(text_sample, str) else \"\"\n",
        "\n",
        "            inputs = tokenizer(\n",
        "                text_sample,\n",
        "                padding=\"max_length\",\n",
        "                truncation=True,\n",
        "                max_length=128,\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(device)\n",
        "\n",
        "            outputs = model(**inputs)\n",
        "            cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "            embeddings[idx] = cls_embedding.cpu()\n",
        "\n",
        "    torch.save(embeddings, save_path)\n",
        "    return embeddings\n",
        "\n",
        "train_text_embeddings = extract_text_embeddings(train_df, \"train_text_embeddings.pt\", text_model, text_tokenizer)\n",
        "val_text_embeddings   = extract_text_embeddings(val_df,   \"val_text_embeddings.pt\",   text_model, text_tokenizer)\n",
        "test_text_embeddings  = extract_text_embeddings(test_df,  \"test_text_embeddings.pt\",  text_model, text_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bTxzSgPR7Ss",
        "outputId": "a5015b79-4eba-4ab8-d213-1c3e93c82e0d"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings already exist at train_text_embeddings.pt\n",
            "Embeddings already exist at val_text_embeddings.pt\n",
            "Embeddings already exist at test_text_embeddings.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Prepare Embeddings (CHANGED for Multi‐Label)\n",
        "# -------------------------------------------------------\n",
        "def prepare_text_embeddings(text_embeddings, df, label_cols=None, has_labels=True):\n",
        "    \"\"\"\n",
        "    For each row in df, gather the text embedding and (optionally) the labels.\n",
        "    label_cols: list of columns for multi-label (e.g. [\"anger\", \"fear\", \"joy\", ...])\n",
        "    \"\"\"\n",
        "    combined_embeddings = []\n",
        "    labels = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        if idx not in text_embeddings:\n",
        "            continue\n",
        "        # Get the [CLS] embedding\n",
        "        text_embedding = text_embeddings[idx].squeeze()  # shape: (768,)\n",
        "        combined_embeddings.append(text_embedding)\n",
        "\n",
        "        if has_labels and label_cols is not None:\n",
        "            # Collect all label columns as a float vector\n",
        "            label_vector = row[label_cols].values.astype(float)  # shape: (5,)\n",
        "            labels.append(label_vector)\n",
        "\n",
        "    # Convert to Tensors\n",
        "    if has_labels and label_cols is not None:\n",
        "        X = torch.stack(combined_embeddings)\n",
        "        Y = torch.tensor(labels, dtype=torch.float)  # multi-label => float\n",
        "        return X, Y\n",
        "    else:\n",
        "        return torch.stack(combined_embeddings)\n",
        "\n",
        "X_train, y_train = prepare_text_embeddings(train_text_embeddings, train_df, LABEL_COLS, has_labels=True)\n",
        "X_val,   y_val   = prepare_text_embeddings(val_text_embeddings,   val_df,   LABEL_COLS, has_labels=True)\n",
        "X_test           = prepare_text_embeddings(test_text_embeddings,  test_df,  LABEL_COLS, has_labels=False)\n",
        "\n",
        "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\n",
        "print(\"X_test: \", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykURmiwuSCBQ",
        "outputId": "aef3bcf9-a5c1-441a-ef65-8af4f9314d18"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: torch.Size([2768, 768]) y_train: torch.Size([2768, 5])\n",
            "X_val:   torch.Size([116, 768]) y_val:   torch.Size([116, 5])\n",
            "X_test:  torch.Size([2767, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def balance_multilabel_data(X, Y):\n",
        "    \"\"\"\n",
        "    Oversample minority label-combinations in a multi-label setting.\n",
        "    1. Convert each row's label vector (like [1,0,1,0,0]) into a tuple (1.0,0.0,1.0,0.0,0.0).\n",
        "    2. Count how many rows share that exact tuple (i.e., label combination).\n",
        "    3. Duplicate those rows until they match the frequency of the most common combination.\n",
        "\n",
        "    NOTE: This lumps each distinct 5-label pattern as one \"class.\"\n",
        "    If every row has a unique pattern, this won't help much.\n",
        "    \"\"\"\n",
        "    from collections import Counter\n",
        "\n",
        "    # Convert each label row to a tuple\n",
        "    label_tuples = [tuple(row.tolist()) for row in Y]\n",
        "    class_counts = Counter(label_tuples)\n",
        "    max_count = max(class_counts.values())\n",
        "\n",
        "    # We'll store duplicates in lists, then convert to tensors\n",
        "    balanced_embeddings = []\n",
        "    balanced_labels = []\n",
        "\n",
        "    for i, label_tuple in enumerate(label_tuples):\n",
        "        balanced_embeddings.append(X[i])\n",
        "        balanced_labels.append(label_tuple)\n",
        "\n",
        "        current_count = class_counts[label_tuple]\n",
        "        # e.g., duplicates_needed = how many times to replicate?\n",
        "        duplicates_needed = int((max_count - current_count) / current_count)\n",
        "\n",
        "        for _ in range(duplicates_needed):\n",
        "            balanced_embeddings.append(X[i])\n",
        "            balanced_labels.append(label_tuple)\n",
        "\n",
        "    balanced_embeddings = torch.stack(balanced_embeddings)\n",
        "    balanced_labels = torch.tensor(balanced_labels, dtype=torch.float)\n",
        "    print(f\"Original dataset size: {X.shape[0]}\")\n",
        "    print(f\"Balanced dataset size: {balanced_embeddings.shape[0]}\")\n",
        "    return balanced_embeddings, balanced_labels\n",
        "\n",
        "# Call our new multi-label balancing function\n",
        "X_train, y_train = balance_multilabel_data(X_train, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oz_zljhMpnm",
        "outputId": "8831f5e6-7127-4836-80ee-2a3b1f0ae663"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: 2768\n",
            "Balanced dataset size: 11158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Define Multi‐Label MLP Model (CHANGED)\n",
        "# -------------------------------------------------------\n",
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_p=0.5):\n",
        "        super(MLPModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(p=dropout_p)\n",
        "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
        "        self.dropout2 = nn.Dropout(p=dropout_p)\n",
        "        self.fc3 = nn.Linear(hidden_dim[1], output_dim)\n",
        "        # For multi‐label, we *do not* apply softmax, we will use BCEWithLogitsLoss\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)            # shape: (batch_size, 5)\n",
        "        # No softmax here for multi‐label. Return raw logits for BCEWithLogitsLoss\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "j2JzYjEHSMu7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model & Hyperparams\n",
        "input_dim    = X_train.shape[1]        # e.g. 768\n",
        "hidden_dim   = [786, 512]             # can be tuned\n",
        "output_dim   = len(LABEL_COLS)        # 5 for multi‐label\n",
        "dropout_p    = 0.3\n",
        "num_epochs   = 50\n",
        "batch_size   = 16\n",
        "learning_rate = 1e-4\n",
        "\n",
        "model = MLPModel(input_dim, hidden_dim, output_dim, dropout_p).to(device)"
      ],
      "metadata": {
        "id": "TSkqLDOVSVyh"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. CHANGED: Use BCEWithLogitsLoss (for multi‐label)\n",
        "# -------------------------------------------------------\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "qeMpwVS2SYam"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Dataloaders\n",
        "# -------------------------------------------------------\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset   = TensorDataset(X_val,   y_val)\n",
        "test_dataset  = TensorDataset(X_test)  # no labels for test\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=batch_size)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "RIiqLiirSbo5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Metrics for Multi‐Label (CHANGED)\n",
        "# -------------------------------------------------------\n",
        "def calculate_metrics(preds, labels):\n",
        "    \"\"\"\n",
        "    preds, labels are lists (or arrays) of shape (N, 5).\n",
        "    We'll do an example with macro avg for PRF.\n",
        "    \"\"\"\n",
        "    preds = np.array(preds)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    # Example: For each label, threshold at 0.5\n",
        "    # (We already do that during loop, but let's be explicit.)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average='macro', zero_division=0\n",
        "    )\n",
        "    # Multi‐label “accuracy” can be ambiguous.\n",
        "    # Some do “exact match ratio”, etc. We'll do a simple overall average:\n",
        "    accuracy = (preds == labels).mean()\n",
        "\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "7biPQklUSeXM"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Train and Validate (CHANGES in Predictions)\n",
        "# -------------------------------------------------------\n",
        "def train_and_save_best_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, save_dir):\n",
        "    best_f1 = -float('inf')\n",
        "    best_model_path = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        all_train_preds, all_train_labels = [], []\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)  # shape: (batch_size, 5)\n",
        "            # For BCEWithLogitsLoss, labels should be float\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Convert logits -> probabilities -> binary predictions\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "            all_train_preds.extend(preds.cpu().tolist())\n",
        "            all_train_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "        # Training metrics\n",
        "        train_accuracy, train_precision, train_recall, train_f1 = calculate_metrics(all_train_preds, all_train_labels)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_val_preds, all_val_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)  # shape: (batch_size, 5)\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                preds = (torch.sigmoid(outputs) > 0.5).float()\n",
        "                all_val_preds.extend(preds.cpu().tolist())\n",
        "                all_val_labels.extend(labels.cpu().tolist())\n",
        "\n",
        "        val_accuracy, val_precision, val_recall, val_f1 = calculate_metrics(all_val_preds, all_val_labels)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}/{num_epochs} \"\n",
        "            f\"Train Loss: {train_loss/len(train_loader):.4f}, \"\n",
        "            f\"Train Acc: {train_accuracy:.4f}, F1: {train_f1:.4f} | \"\n",
        "            f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n",
        "            f\"Val Acc: {val_accuracy:.4f}, F1: {val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Save best model by val_f1\n",
        "        if val_f1 > best_f1:\n",
        "            best_f1 = val_f1\n",
        "            best_model_path = os.path.join(save_dir, f\"best_model_epoch_{epoch+1}_f1_{val_f1:.4f}.pth\")\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "            print(f\"Best model saved with F1: {val_f1:.4f} at epoch {epoch+1}\")\n",
        "\n",
        "    return best_model_path\n",
        "\n",
        "save_dir = \"./models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "best_model_path = train_and_save_best_model(\n",
        "    model, train_loader, val_loader, criterion, optimizer, num_epochs, save_dir\n",
        ")\n",
        "\n",
        "print(f\"Best model saved at: {best_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHid0LPJShaz",
        "outputId": "3e765570-2ac8-45c2-8534-e782233435b9"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 Train Loss: 0.4223, Train Acc: 0.8081, F1: 0.7994 | Val Loss: 0.4952, Val Acc: 0.7776, F1: 0.6444\n",
            "Best model saved with F1: 0.6444 at epoch 1\n",
            "Epoch 2/50 Train Loss: 0.2750, Train Acc: 0.8855, F1: 0.8817 | Val Loss: 0.4974, Val Acc: 0.7828, F1: 0.6369\n",
            "Epoch 3/50 Train Loss: 0.2134, Train Acc: 0.9165, F1: 0.9139 | Val Loss: 0.5380, Val Acc: 0.7724, F1: 0.6219\n",
            "Epoch 4/50 Train Loss: 0.1741, Train Acc: 0.9334, F1: 0.9317 | Val Loss: 0.6094, Val Acc: 0.7724, F1: 0.6228\n",
            "Epoch 5/50 Train Loss: 0.1457, Train Acc: 0.9466, F1: 0.9453 | Val Loss: 0.5935, Val Acc: 0.7810, F1: 0.6237\n",
            "Epoch 6/50 Train Loss: 0.1225, Train Acc: 0.9557, F1: 0.9547 | Val Loss: 0.6019, Val Acc: 0.7828, F1: 0.6133\n",
            "Epoch 7/50 Train Loss: 0.1034, Train Acc: 0.9632, F1: 0.9625 | Val Loss: 0.6853, Val Acc: 0.7776, F1: 0.6271\n",
            "Epoch 8/50 Train Loss: 0.0887, Train Acc: 0.9694, F1: 0.9688 | Val Loss: 0.6955, Val Acc: 0.7793, F1: 0.5938\n",
            "Epoch 9/50 Train Loss: 0.0777, Train Acc: 0.9735, F1: 0.9730 | Val Loss: 0.6954, Val Acc: 0.7914, F1: 0.6319\n",
            "Epoch 10/50 Train Loss: 0.0680, Train Acc: 0.9771, F1: 0.9767 | Val Loss: 0.7624, Val Acc: 0.7828, F1: 0.6210\n",
            "Epoch 11/50 Train Loss: 0.0590, Train Acc: 0.9807, F1: 0.9803 | Val Loss: 0.7515, Val Acc: 0.7966, F1: 0.6472\n",
            "Best model saved with F1: 0.6472 at epoch 11\n",
            "Epoch 12/50 Train Loss: 0.0504, Train Acc: 0.9832, F1: 0.9830 | Val Loss: 0.8341, Val Acc: 0.7828, F1: 0.6203\n",
            "Epoch 13/50 Train Loss: 0.0451, Train Acc: 0.9851, F1: 0.9848 | Val Loss: 0.8226, Val Acc: 0.7862, F1: 0.6057\n",
            "Epoch 14/50 Train Loss: 0.0394, Train Acc: 0.9872, F1: 0.9870 | Val Loss: 0.8363, Val Acc: 0.7862, F1: 0.6015\n",
            "Epoch 15/50 Train Loss: 0.0360, Train Acc: 0.9880, F1: 0.9878 | Val Loss: 0.9190, Val Acc: 0.7810, F1: 0.6291\n",
            "Epoch 16/50 Train Loss: 0.0304, Train Acc: 0.9897, F1: 0.9896 | Val Loss: 0.9071, Val Acc: 0.7948, F1: 0.6221\n",
            "Epoch 17/50 Train Loss: 0.0280, Train Acc: 0.9909, F1: 0.9908 | Val Loss: 0.9498, Val Acc: 0.7897, F1: 0.6121\n",
            "Epoch 18/50 Train Loss: 0.0241, Train Acc: 0.9921, F1: 0.9920 | Val Loss: 1.0402, Val Acc: 0.7828, F1: 0.5914\n",
            "Epoch 19/50 Train Loss: 0.0234, Train Acc: 0.9923, F1: 0.9921 | Val Loss: 1.0208, Val Acc: 0.7966, F1: 0.6316\n",
            "Epoch 20/50 Train Loss: 0.0197, Train Acc: 0.9937, F1: 0.9936 | Val Loss: 1.1363, Val Acc: 0.7845, F1: 0.6105\n",
            "Epoch 21/50 Train Loss: 0.0199, Train Acc: 0.9931, F1: 0.9930 | Val Loss: 1.0813, Val Acc: 0.7983, F1: 0.6315\n",
            "Epoch 22/50 Train Loss: 0.0167, Train Acc: 0.9945, F1: 0.9945 | Val Loss: 1.1466, Val Acc: 0.7828, F1: 0.6228\n",
            "Epoch 23/50 Train Loss: 0.0169, Train Acc: 0.9947, F1: 0.9946 | Val Loss: 1.1681, Val Acc: 0.7845, F1: 0.5951\n",
            "Epoch 24/50 Train Loss: 0.0165, Train Acc: 0.9947, F1: 0.9946 | Val Loss: 1.1242, Val Acc: 0.7914, F1: 0.6054\n",
            "Epoch 25/50 Train Loss: 0.0146, Train Acc: 0.9952, F1: 0.9951 | Val Loss: 1.2035, Val Acc: 0.7914, F1: 0.6174\n",
            "Epoch 26/50 Train Loss: 0.0137, Train Acc: 0.9955, F1: 0.9955 | Val Loss: 1.2861, Val Acc: 0.7793, F1: 0.5723\n",
            "Epoch 27/50 Train Loss: 0.0136, Train Acc: 0.9958, F1: 0.9957 | Val Loss: 1.2511, Val Acc: 0.7862, F1: 0.5881\n",
            "Epoch 28/50 Train Loss: 0.0133, Train Acc: 0.9956, F1: 0.9955 | Val Loss: 1.2265, Val Acc: 0.7966, F1: 0.6136\n",
            "Epoch 29/50 Train Loss: 0.0118, Train Acc: 0.9962, F1: 0.9961 | Val Loss: 1.3126, Val Acc: 0.7879, F1: 0.6151\n",
            "Epoch 30/50 Train Loss: 0.0108, Train Acc: 0.9966, F1: 0.9965 | Val Loss: 1.3052, Val Acc: 0.7966, F1: 0.6164\n",
            "Epoch 31/50 Train Loss: 0.0115, Train Acc: 0.9961, F1: 0.9961 | Val Loss: 1.2877, Val Acc: 0.7879, F1: 0.6099\n",
            "Epoch 32/50 Train Loss: 0.0110, Train Acc: 0.9962, F1: 0.9961 | Val Loss: 1.2857, Val Acc: 0.7897, F1: 0.6129\n",
            "Epoch 33/50 Train Loss: 0.0099, Train Acc: 0.9968, F1: 0.9967 | Val Loss: 1.3380, Val Acc: 0.7845, F1: 0.6070\n",
            "Epoch 34/50 Train Loss: 0.0106, Train Acc: 0.9965, F1: 0.9965 | Val Loss: 1.4059, Val Acc: 0.7759, F1: 0.5812\n",
            "Epoch 35/50 Train Loss: 0.0081, Train Acc: 0.9974, F1: 0.9973 | Val Loss: 1.4286, Val Acc: 0.7897, F1: 0.6211\n",
            "Epoch 36/50 Train Loss: 0.0105, Train Acc: 0.9966, F1: 0.9965 | Val Loss: 1.4429, Val Acc: 0.7810, F1: 0.5640\n",
            "Epoch 37/50 Train Loss: 0.0094, Train Acc: 0.9971, F1: 0.9970 | Val Loss: 1.3980, Val Acc: 0.7793, F1: 0.5800\n",
            "Epoch 38/50 Train Loss: 0.0072, Train Acc: 0.9975, F1: 0.9974 | Val Loss: 1.3831, Val Acc: 0.7897, F1: 0.6064\n",
            "Epoch 39/50 Train Loss: 0.0101, Train Acc: 0.9966, F1: 0.9966 | Val Loss: 1.3904, Val Acc: 0.8000, F1: 0.6411\n",
            "Epoch 40/50 Train Loss: 0.0085, Train Acc: 0.9970, F1: 0.9969 | Val Loss: 1.5295, Val Acc: 0.7879, F1: 0.5995\n",
            "Epoch 41/50 Train Loss: 0.0079, Train Acc: 0.9972, F1: 0.9971 | Val Loss: 1.4739, Val Acc: 0.7810, F1: 0.6090\n",
            "Epoch 42/50 Train Loss: 0.0082, Train Acc: 0.9970, F1: 0.9970 | Val Loss: 1.4779, Val Acc: 0.7966, F1: 0.6408\n",
            "Epoch 43/50 Train Loss: 0.0081, Train Acc: 0.9975, F1: 0.9975 | Val Loss: 1.4925, Val Acc: 0.7931, F1: 0.6086\n",
            "Epoch 44/50 Train Loss: 0.0077, Train Acc: 0.9974, F1: 0.9974 | Val Loss: 1.5805, Val Acc: 0.7931, F1: 0.6218\n",
            "Epoch 45/50 Train Loss: 0.0078, Train Acc: 0.9973, F1: 0.9972 | Val Loss: 1.4792, Val Acc: 0.8017, F1: 0.6480\n",
            "Best model saved with F1: 0.6480 at epoch 45\n",
            "Epoch 46/50 Train Loss: 0.0082, Train Acc: 0.9974, F1: 0.9973 | Val Loss: 1.4921, Val Acc: 0.7948, F1: 0.6577\n",
            "Best model saved with F1: 0.6577 at epoch 46\n",
            "Epoch 47/50 Train Loss: 0.0085, Train Acc: 0.9971, F1: 0.9971 | Val Loss: 1.5474, Val Acc: 0.7914, F1: 0.6150\n",
            "Epoch 48/50 Train Loss: 0.0065, Train Acc: 0.9978, F1: 0.9978 | Val Loss: 1.5450, Val Acc: 0.7931, F1: 0.6223\n",
            "Epoch 49/50 Train Loss: 0.0087, Train Acc: 0.9974, F1: 0.9973 | Val Loss: 1.4699, Val Acc: 0.7948, F1: 0.6295\n",
            "Epoch 50/50 Train Loss: 0.0070, Train Acc: 0.9976, F1: 0.9975 | Val Loss: 1.6087, Val Acc: 0.7966, F1: 0.6323\n",
            "Best model saved at: ./models/best_model_epoch_46_f1_0.6577.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Test Predictions (CHANGES for Multi‐Label)\n",
        "# -------------------------------------------------------\n",
        "def predict_and_generate_submission(test_loader, best_model_path, submission_file_path):\n",
        "    # Reload a fresh model\n",
        "    inference_model = MLPModel(input_dim, hidden_dim, output_dim, dropout_p).to(device)\n",
        "    inference_model.load_state_dict(torch.load(best_model_path))\n",
        "    inference_model.eval()\n",
        "\n",
        "    # We'll store multi‐label predictions as 0/1 for each label\n",
        "    test_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for (inputs,) in test_loader:  # Each batch is a tuple containing only X\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = inference_model(inputs)\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).int()  # shape: (batch_size, 5)\n",
        "            test_predictions.append(preds.cpu())\n",
        "\n",
        "    test_predictions = torch.cat(test_predictions, dim=0).numpy()  # shape: (num_samples, 5)\n",
        "\n",
        "    # Build submission DataFrame\n",
        "    submission_df = pd.DataFrame({\n",
        "        \"id\": test_df[\"id\"],  # or whatever your ID is\n",
        "        \"anger_pred\":    test_predictions[:, 0],\n",
        "        \"fear_pred\":     test_predictions[:, 1],\n",
        "        \"joy_pred\":      test_predictions[:, 2],\n",
        "        \"sadness_pred\": test_predictions[:, 3],\n",
        "        \"surprise_pred\":test_predictions[:, 4]\n",
        "    })\n",
        "\n",
        "    submission_df.to_csv(submission_file_path, index=False)\n",
        "    print(f\"Submission file saved to {submission_file_path}\")\n",
        "    return submission_df\n",
        "\n",
        "submission_file_path = \"submission.csv\"\n",
        "submission_df = predict_and_generate_submission(test_loader, best_model_path, submission_file_path)\n",
        "submission_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "kvMYTGpMSmf9",
        "outputId": "8785d5d4-4b92-4e8d-f869-5fd273b2fff4"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file saved to submission.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       id  anger_pred  fear_pred  joy_pred  sadness_pred  \\\n",
              "0  eng_test_track_a_00001           0          1         0             1   \n",
              "1  eng_test_track_a_00002           0          1         0             1   \n",
              "2  eng_test_track_a_00003           1          1         0             0   \n",
              "3  eng_test_track_a_00004           0          1         0             0   \n",
              "4  eng_test_track_a_00005           0          1         1             1   \n",
              "\n",
              "   surprise_pred  \n",
              "0              0  \n",
              "1              0  \n",
              "2              1  \n",
              "3              0  \n",
              "4              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efb12d4a-6353-4dee-810f-a0b9ecfae945\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>anger_pred</th>\n",
              "      <th>fear_pred</th>\n",
              "      <th>joy_pred</th>\n",
              "      <th>sadness_pred</th>\n",
              "      <th>surprise_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>eng_test_track_a_00001</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eng_test_track_a_00002</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eng_test_track_a_00003</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>eng_test_track_a_00004</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eng_test_track_a_00005</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efb12d4a-6353-4dee-810f-a0b9ecfae945')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-efb12d4a-6353-4dee-810f-a0b9ecfae945 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-efb12d4a-6353-4dee-810f-a0b9ecfae945');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9ec98946-316c-4115-9745-e4b11f30b38b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ec98946-316c-4115-9745-e4b11f30b38b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9ec98946-316c-4115-9745-e4b11f30b38b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission_df",
              "summary": "{\n  \"name\": \"submission_df\",\n  \"rows\": 2767,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2767,\n        \"samples\": [\n          \"eng_test_track_a_01379\",\n          \"eng_test_track_a_00840\",\n          \"eng_test_track_a_02164\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anger_pred\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fear_pred\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"joy_pred\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sadness_pred\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"surprise_pred\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tla8NpESSvNV"
      },
      "execution_count": 70,
      "outputs": []
    }
  ]
}